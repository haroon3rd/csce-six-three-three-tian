{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "633_Machine_Learning_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVIzCUdsHJf9"
      },
      "source": [
        "\n",
        "# CSCE633 Spring 2021 (Total 100 pts)\n",
        "\n",
        "**Machine Learning**\n",
        "\n",
        "**Homework 2**\n",
        "\n",
        "Instructor: Yoonsuck Choe\n",
        "\n",
        "Feb 09, 2021\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcLTh-TG3uaE"
      },
      "source": [
        "**Student name: ** Liu, Tian\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxuMldsVKyjt"
      },
      "source": [
        "# Common instructions (Read carefully)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ09vRUj3kvt"
      },
      "source": [
        "**Submission:**\n",
        "\n",
        "1. After you complete each section, \"Save and pin\" the revision. (**File -> Save and pin revision**). \n",
        "> There will be a 20-point penalty for not including revision history in the submission as instructed below.\n",
        "2. When you're ready to submit, \n",
        "> 1. download the ipynb file (**File -> Download .ipynb**).\n",
        "> 2. take screenshot of revision history, by comparing each successive pinned revisions (there will be several of these: final vs. latest pin, latest pin vs. previous pin, etc.). (**File -> Revision history**, then click on the radio buttons for pinned revisions to compare. Scroll down to the part that shows the major revised part, and take a screenshot. No need to show the entire revision history.)\n",
        "> 3. submit a zip file **lastname-firstname.zip** containing the ipynb file and all revision screenshots.\n",
        "\n",
        "**Using the markup language in the \"text\" boxes:**\n",
        "\n",
        "Note: See https://colab.research.google.com/notebooks/markdown_guide.ipynb#scrollTo=70pYkR9LiOV0 for how to use the markdown when writing your answer in the text boxes.\n",
        "\n",
        "**NEW: Including images/screenshots**\n",
        "\n",
        "When including screenshots directly into the text cell, the markup source can get too long. To avoid this, you can upload your images to good drive, make them publicly viewable, get the share link, get the id string  from the link (for example, 1IDUkDGqQ1xSKOT3Wg8SKgAlKsDIdUQUy), and insert a tag like below:  \n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1IDUkDGqQ1xSKOT3Wg8SKgAlKsDIdUQUy\"> \n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwVHXW2ppfSs"
      },
      "source": [
        "# Section I. Deterministic Case (total 60 points)\n",
        "\n",
        "Consider the following reinforcement learning problem.\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1IDUkDGqQ1xSKOT3Wg8SKgAlKsDIdUQUy\" width=\"250\">\n",
        "<figcaption>Figure 1</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "*   There are 12 states, and the actions are $\\{ up, down, left, right \\}$. Legal actions are those that go to the immediate neighbor, horizontally or vertically (but not diagonally). State $S_8$ is the goal state, and all actions here lead back to itself with reward 0.\n",
        "\n",
        "*   The rewards for all action are 0, except for all actions that lead into $s_8$, which are 100 (as shown in the figure).\n",
        "\n",
        "*   In all cases, assume $\\gamma = 0.9$.\n",
        "\n",
        "* Initially, all $Q(s,a) = 0$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi_b-wLF4v-L"
      },
      "source": [
        "**Problem 1 (Written: 10pts):**\n",
        "\n",
        "Consider the state action sequence of ($s_0$,right), ($s_1$, down), ($s_4$, down), ($s_7$, right), and suppose the $Q(s,a)$ values were updated during each move. \n",
        "\n",
        "(1) Starting with $Q(s,a)=0$ for all $(s,a)$, after one such pass, what would the resulting $Q(s,a)$ values be? \n",
        "* Note: Since one such pass has four actions, four $Q(s,a)$ values will be updated. \n",
        "* Note: Some values may be updated from 0 to 0, but this still counts as an update.  \n",
        "\n",
        "(2) After two such passes, what would be the resulting $Q(s,a)$ values?\n",
        "\n",
        "(3) After three such passes, what would be the resulting $Q(s,a)$ values?\n",
        "\n",
        "(4) After four such passes, what would be the resulting $Q(s,a)$ values?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZogM3XXFZrQ"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "(1) Except $Q(s_7,right) = 100$, all other entries in the $Q(s,a)$ table are 0.\n",
        "\n",
        "(2) Except $Q(s_7,right) = 100$, $Q(s_4,down) = 90$, all other entries in the $Q(s,a)$ table are 0.\n",
        "\n",
        "(3) Except $Q(s_7,right) = 100$, $Q(s_4,down) = 90$, $Q(s_1,down) = 81$, all other entries in the $Q(s,a)$ table are 0.\n",
        "\n",
        "(4) Except $Q(s_7,right) = 100$, $Q(s_4,down) = 90$, $Q(s_1,down) = 81$, $Q(s_0,right) = 72.9$, all other entries in the $Q(s,a)$ table are 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghpOAgZQ2w8F"
      },
      "source": [
        "**Problem 2 (Written: 10pts):**\n",
        "\n",
        "(1) Manually compute the optimal $V^*(s)$ for all states $s_0, s_1, ... s_{11}$. See slide04-rl.pdf, page 14. \n",
        "\n",
        "* The optimal policy $\\pi^*$ is pretty straight-forward: Action that takes you to the next state that is one of the shortest path to the goal state (there could be one, or two or more such paths, depending on yout start state). \n",
        "\n",
        "* It is best if you start from $s_8$ and work backward: s_8, then all states that can reach s_8 in one move (they are $s_5, s_7$, and $s_{11}$), then all states that can reach s_8 in two moves, etc. \n",
        "\n",
        "* Hint: based on how many moves a state $s$ is away from the goal state, $V^*(s)$ has a form of $0 + \\gamma 0 + \\gamma^2 0 + \\gamma^3 100 + \\gamma^4 0 + ... = 0 + 0 + 0 + \\gamma^3 100 + 0 + 0 + ... = \\gamma^3 100 = 0.9^3 * 100 = 72.9$ (in case of four moves).  \n",
        "\n",
        "(2) Manually compute the optimal $Q(s,a)$ for all $(s,a)$. See slide04-rl.pdf, page 26. You can quickly and directly compute this from $V^*(s)$ above. No need to recursively evaluate $Q(s,a)$. \n",
        "\n",
        "* Note: $Q(s,a) = r(s,a) + \\gamma V^*(\\delta(s,a))$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgch2BncIcEq"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "(1)\n",
        "For the goal state $S_8$:  \n",
        "$V^*(S_8) = 0 + \\gamma 0 + \\gamma^2 0 + ... = 0$  \n",
        "\n",
        "For states that can reach $S_8$ in 1 step:  \n",
        "$V^*(S_5) = 100 + \\gamma 0 + \\gamma^2 0 + ... = 100$  \n",
        "$V^*(S_7) = 100 + \\gamma 0 + \\gamma^2 0 + ... = 100$  \n",
        "$V^*(S_{11}) = 100 + \\gamma 0 + \\gamma^2 0 + ... = 100$  \n",
        "\n",
        "For states that can reach $S_8$ in 2 steps:  \n",
        "$V^*(S_{2}) = 0 + \\gamma 100 + \\gamma^2 0 + \\gamma^3 0 + ... = 90$  \n",
        "$V^*(S_{4}) = 0 + \\gamma 100 + \\gamma^2 0 + \\gamma^3 0 + ... = 90$  \n",
        "$V^*(S_{6}) = 0 + \\gamma 100 + \\gamma^2 0 + \\gamma^3 0 + ... = 90$  \n",
        "$V^*(S_{10}) = 0 + \\gamma 100 + \\gamma^2 0 + \\gamma^3 0 + ... = 90$  \n",
        "\n",
        "For states that can reach $S_8$ in 3 steps:  \n",
        "$V^*(S_{1}) = 0 + \\gamma 0 + \\gamma^2 100 + \\gamma^3 0 + ... = 81$  \n",
        "$V^*(S_{3}) = 0 + \\gamma 0 + \\gamma^2 100 + \\gamma^3 0 + ... = 81$  \n",
        "$V^*(S_{9}) = 0 + \\gamma 0 + \\gamma^2 100 + \\gamma^3 0 + ... = 81$\n",
        "\n",
        "For states that can reach $S_8$ in 4 steps:  \n",
        "$V^*(S_{0}) = 0 + \\gamma 0 + \\gamma^2 0 + \\gamma^3 100 + ... = 72.9$  \n",
        "\n",
        "(2)   \n",
        "$Q(s,a)$ table:\n",
        "\n",
        "> States | up  | down | left | right\n",
        "> ---    | --- | ---  | ---  | --- \n",
        "> s0     | -1  | 72.9 | -1   | 72.9\n",
        "> s1     | -1  | 81   |65.61 | 81\n",
        "> s2     | -1  | 90   | 72.9 | -1\n",
        "> s3     |65.61| 81   | -1   | 81\n",
        "> s4     |72.9 | 90   | 72.9 | 90\n",
        "> s5     | 81  | 100  | 81   | -1\n",
        "> s6     |72.9 | 72.9 | -1   | 90\n",
        "> s7     |81   | 81   | 81   | 100\n",
        "> s8     | 0   | 0    | 0    | 0\n",
        "> s9     | 81  | -1   | -1   | 81\n",
        "> s10    | 90  | -1   | 72.9 | 90\n",
        "> s11    | 100 | -1   | 81   | -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euhLzgf-pieu"
      },
      "source": [
        "**Problem 3 (Program: 20 pts):**\n",
        "\n",
        "Modify the fully functioning Q-learning algorithm in the code cell below, to learn the $Q(s,a)$ values for the above\n",
        "example (Figure 1). Use the algorithm in slide04-rl.pdf, Page 22. Note: There are slight differences between the slide and the fully functioning code below. use the code below as the definitive reference. \n",
        "\n",
        "* You have to find out what stopping criterion to use. The code below shows a fixed number of iterations. Change it to something that measures convergence. For exmple, observe the sum of difference in the entire $Q$ table from step $n-1$ to step $n$: $\\sum_{s,a \\in S,A} | Q_n(s,a) - Q_{n-1}(s,a)|$, and stop when the difference drops below a certain level (try 0.01 first, and lower or raise it). You have to find this out empirically.\n",
        "* Use a random policy to select action $a$ given current random state $s$ (note: this is also different from the slide). You will find that this can be achieved by just setting a certain simulation parameter.\n",
        "\n",
        "(1) Directly modify the code below.\n",
        "\n",
        "(2) Show resulting Q table ($12 \\times 4$ matrix).\n",
        "\n",
        "* Rows represent states and columns represent actions.\n",
        "* Row ordering should be $s_0, s_1, s_2, ... , s_{11}$, from top to bottom.\n",
        "* Column ordering should be $up, down, left, right$, from left to right. \n",
        "* **Note: do not change the above ordering! You will be penalized if you do so.**\n",
        "* Set (s,a) of Q and other matrices to $-1$ to mark illegal moves. \n",
        "\n",
        "(3) Write a new function to compute the $V(s)$ values for all $s_0, s_1, ... , s_{11}$, from the resulting $Q(s,a)$ values. Print the $V(s)$ values in the layout of Figure 1. \n",
        "\n",
        "(4) Show a plot showing the running average of $\\sum_{s,a \\in S,A} | Q_{t+1}(s,a) - Q_t(s,a)|$ over the iterations.\n",
        "\n",
        "(5) Compare the outcomes above with the V values and the Q table you manually calculated in problem 2.\n",
        "\n",
        "*). Note: This problem is mostly an exercise of just changing the environment (state transition matrix, and the reward matrix, according to Figure 1). Most of the requirement above, including the Q-table print out, computing the running average of difference in Q over time, and the plotting of the running average are already in the code. Read the instructions at the top of the code cell below, and try running it with different parameters to get your self familiarized with the code. Then change the \"Environment set up\" section where it is marked with \"modify\". The only real code you need to write is to write the function for computing $V(s)$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g85I-5DiBxVp"
      },
      "source": [
        "**Answer**  \n",
        "(1) see the implementation of code below.  \n",
        "(2)(3) Q and V are printed in the output.  \n",
        "(4) see the plot below.  \n",
        "(5) the V and Q calculated by the code are matching with the manually calculated in problem 2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6_lMC5RyuVoo",
        "outputId": "dde4b3cd-de65-42b7-add6-9f7a99c5bdc0"
      },
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "# qlearn.py : simple discrete, deterministic Q-learning \n",
        "#\n",
        "# Requires: numpy, pandas, matplotlib\n",
        "#\n",
        "# Yoonsuck Choe\n",
        "# choe@tamu.edu\n",
        "#\n",
        "# 2021. 02. 17. (wed) 09:00:58 KST\n",
        "# 2021. 02. 18. (thu) 00:09:00 KST\n",
        "#\n",
        "# Getting started:\n",
        "# \n",
        "# - pick between \"console\" mode (for command line) or \"notebook\" mode (for colab, etc). \n",
        "#     See the config section.\n",
        "# \n",
        "#     mode  = \"console\"\n",
        "#\n",
        "# Suggested experiments:\n",
        "#\n",
        "# - change epsilon: \n",
        "#     0.1, 0.25, 0.5 (default), 0.8, 1.0 and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "#    \n",
        "#     ./qlearn.pl --epsilon=0.25 \n",
        "#\n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.epsilon = 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - change alpha: \n",
        "#     0.1, 0.25, 0.5, 0.8, 1.0 (default) and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "# \n",
        "#     ./qlearn.pl --alpha=0.25 \n",
        "# \n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.alpha= 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - try a new grid world environment (change section below \"Environment set up\".\n",
        "#     search for \"modify\"\n",
        "#\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random \n",
        "import argparse, sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#--------------------\n",
        "# config (more config below : search for \"modify\" \n",
        "#\n",
        "# - for colab, etc, use the \"notebook\" mode\n",
        "#--------------------\n",
        "\n",
        "# mode=\"console\"\n",
        "mode=\"notebook\" \n",
        "\n",
        "#--------------------\n",
        "# console mode: process command line arguments\n",
        "#--------------------\n",
        "def parse_args():\n",
        "\n",
        "  cmd = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "  cmd.add_argument('--alpha', type=float, default=\"1.0\", help=\"mixing rate\")\n",
        "  cmd.add_argument('--gamma', type=float, default=\"0.9\", help=\"discount rate\")\n",
        "  cmd.add_argument('--epsilon', type=float, default=\"0.5\", help=\"greedy policy\")\n",
        "  cmd.add_argument('--num_iter', type=int, default=\"300\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--run_avg_rate', type=float, default=\"0.95\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--display_flag', type=str, default=\"True\", help=\"display Q table after each iteration?\")\n",
        "\n",
        "  return cmd.parse_args()\n",
        "\n",
        "#--------------------\n",
        "# notebook mode: process command line arguments\n",
        "#--------------------\n",
        "class argclass:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.alpha = 1.0\n",
        "    self.gamma = 0.9\n",
        "    self.epsilon = 0.5\n",
        "    self.num_iter = 1000\n",
        "    self.run_avg_rate = 0.95\n",
        "    self.tol = 0.01\n",
        "    self.display_flag = \"True\"\n",
        "\n",
        "#--------------------\n",
        "# select mode \n",
        "#--------------------\n",
        "if (mode==\"console\"):\n",
        "\n",
        "  args = parse_args()\n",
        "\n",
        "elif (mode==\"notebook\"):\n",
        "\n",
        "  args = argclass()\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Invalid mode: check the config\")\n",
        "  exit()\n",
        "\n",
        "#--------------------\n",
        "# find sum of abs difference in the two table values\n",
        "#--------------------\n",
        "def df_diff(df1, df2):\n",
        "\n",
        "  d = df1-df2\n",
        "  return d.abs().to_numpy().sum() \n",
        "\n",
        "#--------------------\n",
        "# get optimal V from final Q\n",
        "#--------------------\n",
        "def get_optimalV(Q):\n",
        "  sz = len(Q)\n",
        "  V_optimal = np.zeros(sz)\n",
        "  \n",
        "  for i in range(sz):\n",
        "    V_optimal[i] = Q.iloc[i,:].max()\n",
        "  return V_optimal\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Environment set up : modify this part to change the environment\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "#--------------------\n",
        "# state index : modify\n",
        "#\n",
        "# layout =  (*) marks the goal. \n",
        "# \n",
        "# s0 s1 s2\n",
        "# s3 s4 s5 \n",
        "# s6 s7 (s8)\n",
        "# s9 s10 s11\n",
        "# \n",
        "#   * (s5,down), (s11, up), and (s7,right) has reward 100, all others are 0.\n",
        "#   * All actions in s8 lead back to s8, with reward 0.\n",
        "#\n",
        "#--------------------\n",
        "s_index = [\"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\"] \n",
        "\n",
        "#--------------------\n",
        "# state transition table : modify \n",
        "#--------------------\n",
        "delta = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        " \t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 1, 2, 3, 4, 8, 6, 7, 8]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 3, 4, 5, 6, 7, 8, 9,10, 8,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 1,-1, 3, 4,-1, 6, 8,-1, 9, 10]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 1, 2,-1, 4, 5,-1, 7, 8, 8,10,11,-1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "#--------------------\n",
        "# reward table : modify\n",
        "#--------------------\n",
        "reward = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        "\t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 0, 0, 0, 0, 0, 0, 0, 100]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 0, 0, 0, 0, 0,100,0, 0, 0,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 0,-1, 0, 0, -1,0, 0,-1, 0, 0]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 0, 0,-1, 0, 0,-1, 0,100,0, 0, 0, -1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "print(\"\\n\\nDelta\")\n",
        "print(delta)\n",
        "\n",
        "print(\"\\n\\nReward\")\n",
        "print(reward)\n",
        "\n",
        "#--------------------\n",
        "# goal state : modify\n",
        "#--------------------\n",
        "goal = 8\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Main algorithm : no need to modify much below here (for the deterministic case)\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def qlearn(): \n",
        "\n",
        "  # extract number of states\n",
        "  num_states = len(s_index)\n",
        "  num_actions = 4\n",
        "  \n",
        "  # set up (s,a) visit count\n",
        "  visits = (delta>=0).astype(int)-1\n",
        "  #print(\"\\n\\nvisits:\")\n",
        "  #print(visits)\n",
        "\n",
        "  run_avg = 1\n",
        "  \n",
        "  #--------------------\n",
        "  # (1) Initialize Q table to zeros (-1 for invalid actions)\n",
        "  #\n",
        "  # - Reuse delta table to filter out invalid moves and set others to zero\n",
        "  #--------------------\n",
        " \n",
        "  Q=(delta>=0).astype(float)-1 \n",
        "\n",
        "  old_Q = Q.copy(deep=True) \n",
        "  \n",
        "  print(\"\\n\\nQ: initial\")\n",
        "  print(Q)\n",
        "  \n",
        "  #--------------------\n",
        "  # (2) Main loop\n",
        "  #--------------------\n",
        "  \n",
        "  d = np.zeros(args.num_iter)\n",
        "\n",
        "  n = 0 \n",
        "  while run_avg > args.tol or n < 50:\n",
        "  #for n in range(args.num_iter):\n",
        "    \n",
        "    #----------\n",
        "    # 1. s : randomly select state   \n",
        "    #----------\n",
        "  \n",
        "    s = random.randint(0,num_states-1)\n",
        "  \n",
        "    while (s==goal): # avoid goal state\n",
        "      s = random.randint(0,num_states-1)\n",
        "      \n",
        "    #----------\n",
        "    # 2. a : choose action (epsilon greedy policy)\n",
        "    #----------\n",
        "  \n",
        "    if (random.random() < (1-args.epsilon)):\n",
        "  \n",
        "      # greedy action:\n",
        "      a = Q.iloc[s,:].argmax()\n",
        "  \n",
        "    else:\n",
        "  \n",
        "      # random action\n",
        "      a = random.randint(0,num_actions-1)\n",
        "  \n",
        "      while (delta.iloc[s,a]==-1): # avoid invalid action\n",
        "        a = random.randint(0,num_actions-1)\n",
        "  \n",
        "    #----------\n",
        "    # 3. train\n",
        "    #----------\n",
        "  \n",
        "    visits.iloc[s,a] = visits.iloc[s,a]+1\n",
        "\n",
        "    alpha = args.alpha\n",
        "    gamma = args.gamma\n",
        "  \n",
        "    # 3.1 find next state from (s,a)\n",
        "  \n",
        "    s_next = delta.iloc[s,a]\n",
        "  \n",
        "    # 3.2 update Q\n",
        "  \n",
        "    # Equation is: Q(s,a) = (1-alpha) x Q(s,a) + alpha*( r(s,a) + gamma * max_a' Q(s',a') )\n",
        "    Q.iloc[s,a] = (1.0-alpha)*Q.iloc[s,a] + alpha*(reward.iloc[s,a] + gamma*Q.iloc[s_next,:].max())\n",
        "  \n",
        "  \n",
        "    # 3.3 compute running average of the sum of Q(n) minus Q(n-1)\n",
        "    if n == 0: \n",
        "      run_avg = 0\n",
        "\n",
        "    d[n] = args.run_avg_rate * run_avg + (1-args.run_avg_rate) * df_diff(Q,old_Q)\n",
        "    run_avg = d[n]\n",
        "    old_Q = Q.copy(deep=True)\n",
        "    n += 1 \n",
        "   \n",
        "    # 3.3 print current Q and running average of Q diff.\n",
        "  \n",
        "    if (args.display_flag == \"True\"):\n",
        "  \n",
        "      print(\"\\nQ : iter=\"+str(n-1))\n",
        "      print(Q)\n",
        "      print(\"diff = \"+str(d[n-1]))\n",
        "\n",
        "    #if (n>50  and run_avg < 0.01):\n",
        " \n",
        "    #    break\n",
        "\n",
        "  #--------------------\n",
        "  # (3) Print final Q table  and (s,a) visit count table\n",
        "  #--------------------\n",
        "  print(\"\\nFinal Q table\\n\")\n",
        "  print(Q)\n",
        "  \n",
        "  print(\"\\nFinal visit count table\\n\")\n",
        "  print(visits)\n",
        "  \n",
        "  #--------------------\n",
        "  # (4) Plot diff Q(n), Q(n-1) running average\n",
        "  #--------------------\n",
        "  plt.title(\"Difference in Q table values over time: Running average, rate=\"+str(args.run_avg_rate))\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Diff in Q table values\")\n",
        "  plt.plot(d)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"diff in Q reached below 0.01 at iteration = \"+str(n-1))\n",
        "\n",
        "  #--------------------\n",
        "  # (5) calculate V(s) based on final Q\n",
        "  #--------------------\n",
        "  V_optimal = get_optimalV(Q)\n",
        "  V_optimal = V_optimal.reshape(4,3)\n",
        "  print(\"\\nV_optimal is (in Figure 1 layout):\")\n",
        "  print(V_optimal)\n",
        "\n",
        "\n",
        "#-- end of qlearn() function def\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Run the qlearn main function\n",
        "#\n",
        "# - if you're using notebook mode, you can change the argument and rerun\n",
        "#   in the interactive session (create a new cell and put the following lines in it).\n",
        "#   \n",
        "#    args.epsilon = 0.8\n",
        "#    qlearn()\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "args.display_flag = \"False\"  # Set this to \"True\" to see the changing Q table over time.\n",
        "args.epsilon = 1.0\n",
        "qlearn()\n",
        "\n",
        "# after you run it, check if your Delta (state transition table) and the Reward table are accurate, compared to Figure 1. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Delta\n",
            "     up  down  left  right\n",
            "s0   -1     3    -1      1\n",
            "s1   -1     4     0      2\n",
            "s2   -1     5     1     -1\n",
            "s3    0     6    -1      4\n",
            "s4    1     7     3      5\n",
            "s5    2     8     4     -1\n",
            "s6    3     9    -1      7\n",
            "s7    4    10     6      8\n",
            "s8    8     8     8      8\n",
            "s9    6    -1    -1     10\n",
            "s10   7    -1     9     11\n",
            "s11   8    -1    10     -1\n",
            "\n",
            "\n",
            "Reward\n",
            "      up  down  left  right\n",
            "s0    -1     0    -1      0\n",
            "s1    -1     0     0      0\n",
            "s2    -1     0     0     -1\n",
            "s3     0     0    -1      0\n",
            "s4     0     0     0      0\n",
            "s5     0   100     0     -1\n",
            "s6     0     0    -1      0\n",
            "s7     0     0     0    100\n",
            "s8     0     0     0      0\n",
            "s9     0    -1    -1      0\n",
            "s10    0    -1     0      0\n",
            "s11  100    -1     0     -1\n",
            "\n",
            "\n",
            "Q: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final Q table\n",
            "\n",
            "         up   down   left  right\n",
            "s0    -1.00   72.9  -1.00   72.9\n",
            "s1    -1.00   81.0  65.61   81.0\n",
            "s2    -1.00   90.0  72.90   -1.0\n",
            "s3    65.61   81.0  -1.00   81.0\n",
            "s4    72.90   90.0  72.90   90.0\n",
            "s5    81.00  100.0  81.00   -1.0\n",
            "s6    72.90   72.9  -1.00   90.0\n",
            "s7    81.00   81.0  65.61  100.0\n",
            "s8     0.00    0.0   0.00    0.0\n",
            "s9    81.00   -1.0  -1.00   81.0\n",
            "s10   90.00   -1.0  72.90   90.0\n",
            "s11  100.00   -1.0  81.00   -1.0\n",
            "\n",
            "Final visit count table\n",
            "\n",
            "     up  down  left  right\n",
            "s0   -1    14    -1     14\n",
            "s1   -1    12     8     15\n",
            "s2   -1    19    15     -1\n",
            "s3   12     8    -1      6\n",
            "s4    8    11    11      9\n",
            "s5    8    22     9     -1\n",
            "s6    5     7    -1     12\n",
            "s7    8     6     2      7\n",
            "s8    0     0     0      0\n",
            "s9   13    -1    -1     10\n",
            "s10  10    -1     7      8\n",
            "s11  16    -1    17     -1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "diff in Q reached below 0.01 at iteration = 328\n",
            "\n",
            "V_optimal is (in Figure 1 layout):\n",
            "[[ 72.9  81.   90. ]\n",
            " [ 81.   90.  100. ]\n",
            " [ 90.  100.    0. ]\n",
            " [ 81.   90.  100. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kFhz-tzfRgm"
      },
      "source": [
        "# You can also easily run a different experiment in its own code cell, like below,\n",
        "# with a different set of parameters\n",
        "\n",
        "args.epsilon=0.2\n",
        "qlearn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwwQqSjJ1Iga"
      },
      "source": [
        "**Problem 4 (Program: 10 pts):**\n",
        "\n",
        "Experiment with the $\\epsilon$-greedy policy. You don't need to change any code. Just change the parameter and run qlearn(). \n",
        "\n",
        "Test with different $\\epsilon$ values to see how the $\\epsilon$-greedy policy behaves. For example, $\\epsilon \\in {0.0, 0.1, 0.3, 0.5, 0.8, 0.9, 1.0}$. Note: $\\epsilon = 0.0$ is the greedy policy and $\\epsilon = 1.0$ is the random policy. ($\\epsilon$-greedy chooses the greedy move with $(1-\\epsilon)$ probability.).\n",
        "\n",
        "(1) Which $\\epsilon$ value tend to converge fastest? For each $epsilon$ value, you can run multiple runs (say 5 times) and observe how long it too to converge, and take an average. You can then compare the average. \n",
        "\n",
        "(2) How does the number of visits table differ for different $\\epsilon$ values? Based on this, how do you think $epsilon$ affects exploration vs. exploitation? \n",
        "\n",
        "(3) Did some $\\epsilon$ value lead the algorithm not converging (the final Q table is different from the manually calculated table from Problem 2)? If so, why do you think it did not converge? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giknCWPALGP3"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Run your experiments in the code cell below. \n",
        "\n",
        "(1) Each $\\epsilon$ value is run for 5 times, and the average number of iterations to reach convergence are compared. Results show that $\\epsilon=0.9$ converges fastest. The detailed results are shown in the table below. For $\\epsilon = 0$ case, the iterations were terminated earlier but all the final Q solution are incorrect. For $\\epsilon = 0.1$ and $0.2$ or $0.3$ case, sometimes it also terminated earlier with incorrect final $Q$.\n",
        "\n",
        "> $\\epsilon$ | converge iterations (5 runs) | avg  | note  \n",
        "> ---        | ---                 | ---  | --- \n",
        "> 0          | 138x 147x 161x 127x 122x   | All Q are incorrect  | x means final Q is not correct\n",
        "> 0.1     | 125x 224 914 921 669  |  682  | 1 out of 5 are incorrect\n",
        "> 0.2     | 492 678 139x 130x 908 |  692  | 2 out of 5 are incorrect\n",
        "> 0.3     | 314 431x 594 569 623  | 531 | 1 out of 5 are incorrect\n",
        "> 0.4     | 683 490 495 422 478   | 513   | \n",
        "> 0.5     | 378 461 382 470 638   | 465  | \n",
        "> 0.6     | 377 315 380 419 346   | 367 |   \n",
        "> 0.7     | 389 353 446 430 445   | 412  |    \n",
        "> 0.8     | 377 351 428 392 425   | 394    | \n",
        "> 0.9     | 272 316 275 274 341  | 295   |   Fastest\n",
        "> 1.0    | 393 313 323 273 303   | 321   |   \n",
        "\n",
        "(2) Small $\\epsilon$ values leads more zeros and more concentrated values in the visit table, i.e. less $(s,a)$ pairs were visited. On the contrary, large $\\epsilon$ values result in much less zeros and more spreaded values in the visit table, i.e. more $(s,a)$ pairs were visited more evenly. Thus, large $\\epsilon$ means more random search, i.e. more exploration. And small $\\epsilon$ controls more greedy search, i.e. more exploitation.\n",
        "\n",
        "(3) As shown in the table above, when $\\epsilon = 0$, the algorithm is not converging. And when $\\epsilon = 0.1\\ or\\ 0.2\\ or\\ 0.3 $, the algorithm is not converging some times as well. This is because small $\\epsilon$ results in strong greedy search in each iteration. And initially, the Q table is mostly 0 and -1. Taking the greedy action (taking the action with largest $Q(s,a)$ value) will always take the first action with 0 in the Q table. So after several iterations, only few $(s,a)$ paris were visited and updated. This constraints the algorithm to visit different $(s,a)$ pairs, leading to not converging or converging to incorrect solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BYxGGNnaKfOJ",
        "outputId": "93bad790-de34-41a2-f433-f7c9b816834c"
      },
      "source": [
        "# You can quickly run multiple experiments without modifying the code above or copying and pasting the whole code. Just do something like this. Create a new code cell for a different experiment.\n",
        "\n",
        "# Q=(delta>0).astype(float)-1.0 + (delta>0)*np.random.rand(6,4)*0.001   # add small initial random value to break the tie \n",
        "args.display_flag = \"False\"\n",
        "args.epsilon = 0.1\n",
        "qlearn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Q: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final Q table\n",
            "\n",
            "        up  down  left  right\n",
            "s0    -1.0   0.0  -1.0    0.0\n",
            "s1    -1.0   0.0   0.0    0.0\n",
            "s2    -1.0   0.0   0.0   -1.0\n",
            "s3     0.0   0.0  -1.0    0.0\n",
            "s4     0.0   0.0   0.0    0.0\n",
            "s5     0.0   0.0   0.0   -1.0\n",
            "s6     0.0   0.0  -1.0    0.0\n",
            "s7     0.0   0.0   0.0    0.0\n",
            "s8     0.0   0.0   0.0    0.0\n",
            "s9     0.0  -1.0  -1.0    0.0\n",
            "s10    0.0  -1.0   0.0    0.0\n",
            "s11  100.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final visit count table\n",
            "\n",
            "     up  down  left  right\n",
            "s0   -1    18    -1      1\n",
            "s1   -1    14     1      0\n",
            "s2   -1     4     1     -1\n",
            "s3   11     0    -1      1\n",
            "s4   11     0     0      0\n",
            "s5    8     0     0     -1\n",
            "s6   13     1    -1      0\n",
            "s7   10     0     0      0\n",
            "s8    0     0     0      0\n",
            "s9   16    -1    -1      0\n",
            "s10  10    -1     0      0\n",
            "s11  10    -1     0     -1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "diff in Q reached below 0.01 at iteration = 129\n",
            "\n",
            "V_optimal is (in Figure 1 layout):\n",
            "[[  0.   0.   0.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0. 100.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnbIHjJydfDO"
      },
      "source": [
        "**Answer:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3kArrZgDWAJ"
      },
      "source": [
        "**Problem 5 (Programming: 10)**\n",
        "\n",
        "Copy and paste the code in Problem 3, and change it to implement SARSA($\\lambda$). You have to make sure you implement the eligibility trace correctly. \n",
        "\n",
        "Once you're done implementing, run a few experiments to determine whether the original Q learning in Problem 3 works faster, or if the SARSA($\\lambda$) algorithm works faster (faster to converge, given the same parameter conditions). The results may vary. Please write a detailed description of you experiment and results, and whether you find the more sophisticated SARSA($\\lambda$) to be faster to converge. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANnJJ3b1D7iW"
      },
      "source": [
        "**Answer**  \n",
        "The origional Q learning and the SARSA($\\lambda$) are compared as shown in the code cells below. The SARSA($\\lambda$) are ran for multiple times to find the best parameters for it to converge and get closely correct $Q$. The found parameters are the following:\n",
        "```\n",
        "args.epsilon = 0.2  \n",
        "args.alpha = 0.05  \n",
        "args.lamda = 0.9  \n",
        "args.gamma = 0.9  \n",
        "args.num_iter = 10000\n",
        "args.run_avg_rate = 0.99\n",
        "args.tol = 0.1\n",
        "```\n",
        "The Q learning used the same parameters except $args.alpha = 1$. If using the same small $alpha = 0.05$ as in the $SARSA(\\lambda) $, the Q learning will terminate with few iterations due to the small update at each step. Thus, $alpha =1$ is used for Q learning to get correct $Q$.   \n",
        "\n",
        "The results show that the Q learning converged after 1149 iterations as shown below. However, the $SARSA(\\lambda)$ stopped only after reaching the max number of iterations (10000). This is because that at each move, all the $Q(s,a)$ pairs along the same trace are updated, causing the difference in Q tables hard to meet the stopping/converging criteria. The $Q$ output by $SARSA(\\lambda)$ does not exactly equal to the $Q$ as gernerated by the origonal Q learning, but approximately correct.\n",
        "\n",
        "Thus, for this problem, the $SARSA(\\lambda)$ is not converging faster than the origional Q learning algorithm. Probably it is because this is a small problem with simple $Q$ table and short traces. In more complicated problems with large $Q$ table and longer traces, I believe that $SARSA(\\lambda)$ would perform better than the origional Q learning. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jtEbO4VEwFBg",
        "outputId": "b4972442-7c54-4627-b60a-eba7d764617b"
      },
      "source": [
        "# run the origional Q learn with the same parameters as SARSA(lambda)\n",
        "args.display_flag = \"False\"\n",
        "args.epsilon = 0.2\n",
        "args.alpha = 1\n",
        "args.gamma = 0.9\n",
        "args.run_avg_rate = 0.99\n",
        "args.num_iter = 10000\n",
        "args.tol =0.1\n",
        "\n",
        "qlearn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Q: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final Q table\n",
            "\n",
            "         up   down   left  right\n",
            "s0    -1.00   72.9  -1.00   72.9\n",
            "s1    -1.00   81.0  65.61   81.0\n",
            "s2    -1.00   90.0  72.90   -1.0\n",
            "s3    65.61   81.0  -1.00   81.0\n",
            "s4    72.90   90.0  72.90   90.0\n",
            "s5    81.00  100.0  81.00   -1.0\n",
            "s6    72.90   72.9  -1.00   90.0\n",
            "s7    81.00   81.0  81.00  100.0\n",
            "s8     0.00    0.0   0.00    0.0\n",
            "s9    81.00   -1.0  -1.00   81.0\n",
            "s10   90.00   -1.0  72.90   90.0\n",
            "s11  100.00   -1.0  81.00   -1.0\n",
            "\n",
            "Final visit count table\n",
            "\n",
            "      up  down  left  right\n",
            "s0    -1    46    -1     38\n",
            "s1    -1    83     3     32\n",
            "s2    -1    89    12     -1\n",
            "s3    38    45    -1     19\n",
            "s4    45    42     5     23\n",
            "s5     5    86     3     -1\n",
            "s6    36     1    -1     53\n",
            "s7     9     8     5     97\n",
            "s8     0     0     0      0\n",
            "s9    66    -1    -1     42\n",
            "s10   90    -1     9      3\n",
            "s11  105    -1    12     -1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "diff in Q reached below 0.01 at iteration = 1149\n",
            "\n",
            "V_optimal is (in Figure 1 layout):\n",
            "[[ 72.9  81.   90. ]\n",
            " [ 81.   90.  100. ]\n",
            " [ 90.  100.    0. ]\n",
            " [ 81.   90.  100. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSZlz-J8v86N",
        "outputId": "d0ed26d6-19e0-45a1-f742-3374a890b226"
      },
      "source": [
        "# SARSA(lambda)\n",
        "\n",
        "\n",
        "#!/usr/bin/python\n",
        "\n",
        "# qlearn.py : simple discrete, deterministic Q-learning \n",
        "#\n",
        "# Requires: numpy, pandas, matplotlib\n",
        "#\n",
        "# Yoonsuck Choe\n",
        "# choe@tamu.edu\n",
        "#\n",
        "# 2021. 02. 17. (wed) 09:00:58 KST\n",
        "# 2021. 02. 18. (thu) 00:09:00 KST\n",
        "#\n",
        "# Getting started:\n",
        "# \n",
        "# - pick between \"console\" mode (for command line) or \"notebook\" mode (for colab, etc). \n",
        "#     See the config section.\n",
        "# \n",
        "#     mode  = \"console\"\n",
        "#\n",
        "# Suggested experiments:\n",
        "#\n",
        "# - change epsilon: \n",
        "#     0.1, 0.25, 0.5 (default), 0.8, 1.0 and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "#    \n",
        "#     ./qlearn.pl --epsilon=0.25 \n",
        "#\n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.epsilon = 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - change alpha: \n",
        "#     0.1, 0.25, 0.5, 0.8, 1.0 (default) and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "# \n",
        "#     ./qlearn.pl --alpha=0.25 \n",
        "# \n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.alpha= 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - try a new grid world environment (change section below \"Environment set up\".\n",
        "#     search for \"modify\"\n",
        "#\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random \n",
        "import argparse, sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#--------------------\n",
        "# config (more config below : search for \"modify\" \n",
        "#\n",
        "# - for colab, etc, use the \"notebook\" mode\n",
        "#--------------------\n",
        "\n",
        "# mode=\"console\"\n",
        "mode=\"notebook\" \n",
        "\n",
        "#--------------------\n",
        "# console mode: process command line arguments\n",
        "#--------------------\n",
        "def parse_args():\n",
        "\n",
        "  cmd = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "  cmd.add_argument('--alpha', type=float, default=\"1.0\", help=\"mixing rate\")\n",
        "  cmd.add_argument('--gamma', type=float, default=\"0.9\", help=\"discount rate\")\n",
        "  cmd.add_argument('--epsilon', type=float, default=\"0.5\", help=\"greedy policy\")\n",
        "  cmd.add_argument('--num_iter', type=int, default=\"300\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--run_avg_rate', type=float, default=\"0.95\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--display_flag', type=str, default=\"True\", help=\"display Q table after each iteration?\")\n",
        "\n",
        "  return cmd.parse_args()\n",
        "\n",
        "#--------------------\n",
        "# notebook mode: process command line arguments\n",
        "#--------------------\n",
        "class argclass:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.alpha = 0.05\n",
        "    self.lamda = 0.9\n",
        "    self.gamma = 0.9\n",
        "    self.epsilon = 1.0\n",
        "    self.num_iter = 10000\n",
        "    self.run_avg_rate = 0.9\n",
        "    self.tol = 0.01\n",
        "    self.display_flag = \"True\"\n",
        "\n",
        "#--------------------\n",
        "# select mode \n",
        "#--------------------\n",
        "if (mode==\"console\"):\n",
        "\n",
        "  args = parse_args()\n",
        "\n",
        "elif (mode==\"notebook\"):\n",
        "\n",
        "  args = argclass()\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Invalid mode: check the config\")\n",
        "  exit()\n",
        "\n",
        "#--------------------\n",
        "# find sum of abs difference in the two table values\n",
        "#--------------------\n",
        "def df_diff(df1, df2):\n",
        "\n",
        "  d = df1-df2\n",
        "  return d.abs().to_numpy().sum() \n",
        "\n",
        "#--------------------\n",
        "# get optimal V from final Q\n",
        "#--------------------\n",
        "def get_optimalV(Q):\n",
        "  sz = len(Q)\n",
        "  V_optimal = np.zeros(sz)\n",
        "  \n",
        "  for i in range(sz):\n",
        "    V_optimal[i] = Q.iloc[i,:].max()\n",
        "  return V_optimal\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Environment set up : modify this part to change the environment\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "#--------------------\n",
        "# state index : modify\n",
        "#\n",
        "# layout =  (*) marks the goal. \n",
        "# \n",
        "# s0 s1 s2\n",
        "# s3 s4 s5 \n",
        "# s6 s7 (s8)\n",
        "# s9 s10 s11\n",
        "# \n",
        "#   * (s5,down), (s11, up), and (s7,right) has reward 100, all others are 0.\n",
        "#   * All actions in s8 lead back to s8, with reward 0.\n",
        "#\n",
        "#--------------------\n",
        "s_index = [\"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\"] \n",
        "\n",
        "#--------------------\n",
        "# state transition table : modify \n",
        "#--------------------\n",
        "delta = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        " \t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 1, 2, 3, 4, 8, 6, 7, 8]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 3, 4, 5, 6, 7, 8, 9,10, 8,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 1,-1, 3, 4,-1, 6, 8,-1, 9, 10]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 1, 2,-1, 4, 5,-1, 7, 8, 8,10,11,-1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "#--------------------\n",
        "# reward table : modify\n",
        "#--------------------\n",
        "reward = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        "\t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 0, 0, 0, 0, 0, 0, 0, 100]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 0, 0, 0, 0, 0,100,0, 0, 0,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 0,-1, 0, 0,-1, 0, 0,-1, 0, 0]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 0, 0,-1, 0, 0,-1, 0,100,0, 0, 0, -1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "print(\"\\n\\nDelta\")\n",
        "print(delta)\n",
        "\n",
        "print(\"\\n\\nReward\")\n",
        "print(reward)\n",
        "\n",
        "#--------------------\n",
        "# goal state : modify\n",
        "#--------------------\n",
        "goal = 8\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Main algorithm : no need to modify much below here (for the deterministic case)\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def qlearn_sarsa_l(): \n",
        "\n",
        "  # extract number of states\n",
        "  num_states = len(s_index)\n",
        "  num_actions = 4\n",
        "  \n",
        "  # set up (s,a) visit count\n",
        "  visits = (delta>=0).astype(int)-1\n",
        "  #print(\"\\n\\nvisits:\")\n",
        "  #print(visits)\n",
        "\n",
        "  run_avg = 1\n",
        "  \n",
        "  #--------------------\n",
        "  # (1) Initialize Q table to zeros (-1 for invalid actions)\n",
        "  #\n",
        "  # - Reuse delta table to filter out invalid moves and set others to zero\n",
        "  #--------------------\n",
        " \n",
        "  Q=(delta>=0).astype(float)-1 \n",
        "\n",
        "  old_Q = Q.copy(deep=True) \n",
        "  \n",
        "  print(\"\\n\\nQ: initial\")\n",
        "  print(Q)\n",
        "  \n",
        "  #--------------------\n",
        "  # (2) Main loop\n",
        "  #--------------------\n",
        "  \n",
        "  d = np.zeros(args.num_iter)\n",
        "\n",
        "  n = 0 \n",
        "  while (run_avg > args.tol or n < 50) and n< args.num_iter :\n",
        "  #for n in range(args.num_iter):\n",
        "    \n",
        "    # reset the eligibility trace table to 0 for each episod\n",
        "    E = pd.DataFrame(\n",
        "      {                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        "        \"up\"   : pd.Series(np.array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),index=s_index),\n",
        "        \"down\" : pd.Series(np.array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),index=s_index),\n",
        "        \"left\" : pd.Series(np.array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),index=s_index),\n",
        "        \"right\": pd.Series(np.array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),index=s_index)\n",
        "      }\n",
        "    )\n",
        "\n",
        "    #----------\n",
        "    # 1. s : randomly select state   \n",
        "    #----------\n",
        "  \n",
        "    s = random.randint(0,num_states-1)\n",
        "  \n",
        "    while (s==goal): # avoid goal state\n",
        "      s = random.randint(0,num_states-1)\n",
        "    \n",
        "    #----------\n",
        "    # 2. a : choose action (epsilon greedy policy)\n",
        "    #----------\n",
        "  \n",
        "    if (random.random() < (1-args.epsilon)):\n",
        "  \n",
        "      # greedy action:\n",
        "      a = Q.iloc[s,:].argmax()\n",
        "  \n",
        "    else:\n",
        "  \n",
        "      # random action\n",
        "      a = random.randint(0,num_actions-1)\n",
        "  \n",
        "      while (delta.iloc[s,a]==-1): # avoid invalid action\n",
        "        a = random.randint(0,num_actions-1)\n",
        "  \n",
        "    while s != goal: # keep seaching until reaching goal state\n",
        "      #----------\n",
        "      # 3. train\n",
        "      #----------\n",
        "    \n",
        "      visits.iloc[s,a] = visits.iloc[s,a]+1\n",
        "\n",
        "      alpha = args.alpha\n",
        "      gamma = args.gamma\n",
        "    \n",
        "      # 3.1 find next state from (s,a)\n",
        "    \n",
        "      s_next = delta.iloc[s,a]\n",
        "\n",
        "      # pick next action a_next based on greedy policy\n",
        "      if (random.random() < (1-args.epsilon)):  \n",
        "        # greedy action:\n",
        "        a_next = Q.iloc[s_next,:].argmax()\n",
        "      else:\n",
        "        # random action\n",
        "        a_next = random.randint(0,num_actions-1)\n",
        "  \n",
        "      while (delta.iloc[s_next,a_next]==-1): # avoid invalid action\n",
        "        a_next = random.randint(0,num_actions-1)\n",
        "      \n",
        "      dlta = reward.iloc[s,a] + gamma*Q.iloc[s_next,a_next] - Q.iloc[s,a]\n",
        "      E.iloc[s,a] = 1\n",
        "   \n",
        "      # update all (s,a) based on Eglibility trace\n",
        "      alpha = args.alpha\n",
        "      lamda = args.lamda\n",
        "      for ss in range(len(Q)):\n",
        "        for aa in range(num_actions): \n",
        "          if E.iloc[ss,aa] != 0:\n",
        "            #Q.iloc[ss,aa] += np.power(0.9,n)*alpha*dlta*E.iloc[ss,aa]\n",
        "            Q.iloc[ss,aa] += alpha*dlta*E.iloc[ss,aa]\n",
        "            E.iloc[ss,aa] *= gamma*lamda\n",
        "      \n",
        "      s = s_next\n",
        "      a = a_next    \n",
        "  \n",
        "      # Equation is: Q(s,a) = (1-alpha) x Q(s,a) + alpha*( r(s,a) + gamma * max_a' Q(s',a') )\n",
        "      #Q.iloc[s,a] = (1.0-alpha)*Q.iloc[s,a] + alpha*(reward.iloc[s,a] + gamma*Q.iloc[s_next,:].max())\n",
        "      \n",
        "      # end of one trace\n",
        "    \n",
        "    # 3.3 compute running average of the sum of Q(n) minus Q(n-1)\n",
        "    if n == 0: \n",
        "      tun_avg = 0\n",
        "      \n",
        "    d[n] = args.run_avg_rate * run_avg + (1-args.run_avg_rate) * df_diff(Q,old_Q)\n",
        "    run_avg = d[n]\n",
        "    old_Q = Q.copy(deep=True)\n",
        "\n",
        "    n += 1 \n",
        "   \n",
        "    # 3.3 print current Q and running average of Q diff.\n",
        "  \n",
        "    if (args.display_flag == \"True\"):\n",
        "  \n",
        "      print(\"\\nQ : iter=\"+str(n-1))\n",
        "      print(Q)\n",
        "      print(\"diff = %f\" % d[n-1])\n",
        "      #if n ==100:\n",
        "      #  stop\n",
        "      #print('Visit')\n",
        "      #print(visits)\n",
        "      #print(\"run_avg = \"+str(d[n-1]))\n",
        "\n",
        "    #if (n>50  and run_avg < 0.01):\n",
        " \n",
        "    #    break\n",
        "\n",
        "  #--------------------\n",
        "  # (3) Print final Q table  and (s,a) visit count table\n",
        "  #--------------------\n",
        "  print(\"\\nFinal Q table\\n\")\n",
        "  print(Q)\n",
        "  \n",
        "  print(\"\\nFinal visit count table\\n\")\n",
        "  print(visits)\n",
        "  \n",
        "  #--------------------\n",
        "  # (4) Plot diff Q(n), Q(n-1) running average\n",
        "  #--------------------\n",
        "  plt.title(\"Difference in Q table values over time: Running average, rate=\"+str(args.run_avg_rate))\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Diff in Q table values\")\n",
        "  plt.plot(d)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"diff in Q reached below 0.01 at iteration = \"+str(n-1))\n",
        "\n",
        "  #--------------------\n",
        "  # (5) calculate V(s) based on final Q\n",
        "  #--------------------\n",
        "  V_optimal = get_optimalV(Q)\n",
        "  V_optimal = V_optimal.reshape(4,3)\n",
        "  print(\"\\nV_optimal is (in Figure 1 layout):\")\n",
        "  print(V_optimal)\n",
        "\n",
        "\n",
        "#-- end of qlearn() function def\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Run the qlearn main function\n",
        "#\n",
        "# - if you're using notebook mode, you can change the argument and rerun\n",
        "#   in the interactive session (create a new cell and put the following lines in it).\n",
        "#   \n",
        "#    args.epsilon = 0.8\n",
        "#    qlearn()\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "args.display_flag = \"False\"  # Set this to \"True\" to see the changing Q table over time.\n",
        "args.epsilon = 0.2\n",
        "args.alpha = 0.05\n",
        "args.lamda = 0.9\n",
        "\n",
        "args.gamma = 0.9\n",
        "args.num_iter = 10000\n",
        "args.run_avg_rate = 0.99\n",
        "args.tol = 0.1\n",
        "\n",
        "qlearn_sarsa_l()\n",
        "\n",
        "# after you run it, check if your Delta (state transition table) and the Reward table are accurate, compared to Figure 1. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Delta\n",
            "     up  down  left  right\n",
            "s0   -1     3    -1      1\n",
            "s1   -1     4     0      2\n",
            "s2   -1     5     1     -1\n",
            "s3    0     6    -1      4\n",
            "s4    1     7     3      5\n",
            "s5    2     8     4     -1\n",
            "s6    3     9    -1      7\n",
            "s7    4    10     6      8\n",
            "s8    8     8     8      8\n",
            "s9    6    -1    -1     10\n",
            "s10   7    -1     9     11\n",
            "s11   8    -1    10     -1\n",
            "\n",
            "\n",
            "Reward\n",
            "      up  down  left  right\n",
            "s0    -1     0    -1      0\n",
            "s1    -1     0     0      0\n",
            "s2    -1     0     0     -1\n",
            "s3     0     0    -1      0\n",
            "s4     0     0     0      0\n",
            "s5     0   100     0     -1\n",
            "s6     0     0    -1      0\n",
            "s7     0     0     0    100\n",
            "s8     0     0     0      0\n",
            "s9     0    -1    -1      0\n",
            "s10    0    -1     0      0\n",
            "s11  100    -1     0     -1\n",
            "\n",
            "\n",
            "Q: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final Q table\n",
            "\n",
            "             up        down       left       right\n",
            "s0    -1.000000   68.442081  -1.000000   66.945564\n",
            "s1    -1.000000   78.627690  61.739226   74.642141\n",
            "s2    -1.000000   87.722669  67.955782   -1.000000\n",
            "s3    61.953265   76.406608  -1.000000   74.008164\n",
            "s4    69.630089   85.386127  68.437559   88.234514\n",
            "s5    75.914590  100.000000  78.340563   -1.000000\n",
            "s6    67.533135   70.846149  -1.000000   86.767608\n",
            "s7    77.445927   78.399500  73.812117  100.000000\n",
            "s8     0.000000    0.000000   0.000000    0.000000\n",
            "s9    76.517741   -1.000000  -1.000000   79.448416\n",
            "s10   86.051026   -1.000000  70.775210   89.391217\n",
            "s11  100.000000   -1.000000  79.620522   -1.000000\n",
            "\n",
            "Final visit count table\n",
            "\n",
            "       up  down  left  right\n",
            "s0     -1   912    -1    313\n",
            "s1     -1   841   136   1207\n",
            "s2     -1  2263   267     -1\n",
            "s3    147   354    -1   1678\n",
            "s4    668   954   230   2668\n",
            "s5    398  5140   365     -1\n",
            "s6    115   107    -1   1315\n",
            "s7    737   181   183   2355\n",
            "s8      0     0     0      0\n",
            "s9    122    -1    -1    997\n",
            "s10   301    -1   132   1892\n",
            "s11  2505    -1   250     -1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "diff in Q reached below 0.01 at iteration = 9999\n",
            "\n",
            "V_optimal is (in Figure 1 layout):\n",
            "[[ 68.44208074  78.62768979  87.72266905]\n",
            " [ 76.40660764  88.23451355 100.        ]\n",
            " [ 86.76760834 100.           0.        ]\n",
            " [ 79.44841612  89.3912172  100.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxCLvEm918y2"
      },
      "source": [
        "# Section II. Stochastic Case (total 40 points)\n",
        "\n",
        "Consider a stochastic version of the reinforcement learning problem posed in Section 1 (figure copie below). Modify the rules so that:\n",
        "\n",
        "* $\\delta(s,a)$ is stochastic: The probability of landing in the intended direction is $0.70$. The probability of landing in one of $n$ unintended legal direction is $\\frac{0.30}{n}$.\n",
        "\n",
        "  * Example 1 : If you are in $s_0$ and action $a$ was $right$, probability of landing in $s_1$ is 0.70, and ending up in $s_3$ u=is 0.3.\n",
        "\n",
        "  * Example 2: If you are in $s_1$ and $a$ was $down$, probability of landing in $s_4$ is 0.70, ending up in $s_0$ is 0.15 (= 0.3/2), and ending up in $s_2$ is 0.15 (= 0.3/2).\n",
        "\n",
        "  * Example 3: If you are in $s_4$ and $a$ was $left$, probability of landing in $s_3$ is 0.70, ending up in $s_1$ is 0.1 (= 0.3/3), ending up in $s_5$ is 0.1 (= 0.3/3), and ending up in $s_7$ is 0.1 (= 0.3/3)\n",
        "\n",
        "* Reward $r(s,a)$ depends on where you landed based on the above. All rewards are 0 unless the resulting state was the goal state $s_8$. For example, if you were in $s_7$ and the action was $a=up$, with 10\\% chance you will land in $s_8$, the goal state. In this case $r(s_7, up) = 100$ for that specific run. In a different run, with the same action $up$, if you landed in $s_{10}$, then $r(s_7,up) = 0$. Note that $r(s_7,up)$ can be either 0 or 100, depending on the random outcome.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1IDUkDGqQ1xSKOT3Wg8SKgAlKsDIdUQUy\" height=\"450px\"> &nbsp;&nbsp;&nbsp; &nbsp;<img \n",
        " src=\"https://drive.google.com/uc?export=view&id=1aGu78DvllvjaDghW7fzNK7uOPeBmebyN\" height=\"450px\"> \n",
        "<figcaption>Figure 2: Left = same as Figure 1, Right = stochastic behavior </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-XlIERHSFv6"
      },
      "source": [
        "**Problem 7 (Written: 10 pts):**\n",
        "\n",
        "Compute $E[r(s_7,up)]$ by hand, given the above info (Figure 2, and the description).\n",
        "\n",
        "$E[\\cdot]$ is the expected value operator. $E[X] = \\sum_{i=0}^n x_i p_i $, where $X$ is a random variable, $x_i$ ($i=0 .. n$) is a value $X$ can take, and $p_i$ is the probability of observing $x_i$.  \n",
        "\n",
        "So, to compute $E[r(s_7,up)]$, you need to find all possible reward values ($x_i$) and their probabilities ($p_i$), then plug it into the above equation. See Figure 2 (right) to find these values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_dTXhEfVMil"
      },
      "source": [
        "**Answer**:  \n",
        "$E[r(s_7,up)] = sum_{i=0}^n r_i p_i = 0*0.7 + 100*0.1 + 0*0.1 + 0*0.1 = 10$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOYVoYGg2CrN"
      },
      "source": [
        "**Problem 8 (Program: 20 pts):**\n",
        "\n",
        "Modify the program in problem 3, so that the environment acts stochastically, as defined in the beginning of section II. \n",
        "\n",
        "The learning rule has to be modified to the one shown in slide04-rl.pdf, page 35. \n",
        "\n",
        "> $\\hat{Q}_n(s,a) \\leftarrow (1-\\alpha_n) \\hat{Q}_{n-1}(s,a) + \\alpha_n \\left[ r + \\gamma \\max_{a'} \\hat{Q}_{n-1}(s',a') \\right],$ \n",
        "> \n",
        "> where $\\alpha_n = \\frac{1}{1+visits_s(s,a)}$\n",
        "\n",
        "(1) Modify the code from problem 3.\n",
        "\n",
        "(2) Run the experiment, and show the resulting $Q$ table. You should experiment with the $\\alpha$ parameter to get the correct result. Use the random policy. $\\gamma = 0.9$, as usual.  \n",
        "\n",
        "(3) Set up another table Sum_Ersa to compute the sum of all reward you observed when visiting the $(s,a)$ pairs. This table should be the same size as the Q table. When a specific state action pair is visited ($(s,a)$ is \"visited\", when $s$ and $a$ are randomly generated in the main loop, to update $Q(s,a)$), say $(s_4, right)$, observe the reward ($r$), and add it to the appropriate Sum_Ersa location:\n",
        "```\n",
        "Sum_Ersa.iloc[5,3] = r + Sum_Ersa.iloc[5,3]    # Note: (index of s4 is 5, and index of right is 3)\n",
        "```\n",
        "or\n",
        "```\n",
        "Sum_Ersa.loc[\"s4\",\"right\"] = r + Sum_Ersa.loc[\"s4\",\"right\"]    # Using loc, instead of iloc.\n",
        "```\n",
        "Finally, after your training terminates, compute an estimate of $E[r(s,a)]$, based on the Sum_Ersa  table and the visits table (this visits table is already implemented). \n",
        "\n",
        "> $E[r(s,a)] \\sim \\frac{\\sum_{\\forall \\mbox{visits to } (s,a)} (\\mbox{observed  reward }, r)}{\\mbox{visits}(s,a)}$\n",
        "\n",
        "Store the results in a table named:\n",
        "```\n",
        "Ersa\n",
        "```\n",
        "\n",
        "Print out the results.\n",
        "\n",
        "(4) Compare $E[r(s_7,up)]$ with the manually computed value from Problem 7. Are they comparable?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQr8LcjPgY4P"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "(1) Please see the implementation in the code cell below.\n",
        "\n",
        "(2) Please see the final Q table in the output of the following cell code.\n",
        "\n",
        "(3) Sum_Ersa and Ersa are both printed out in the output below.\n",
        "\n",
        "(4) From the output Ersa table, $E[r(s_7,up)]=10.21$, which is comparable to the manually calculated value of $10$ in Problem 7 above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zRKMMyJbvkWo",
        "outputId": "98bf1a0f-3690-4d8e-b127-95a9451ba82b"
      },
      "source": [
        "# Write your code here, for the nondeterministic Q-learning algorithm.\n",
        "\n",
        "#!/usr/bin/python\n",
        "\n",
        "# qlearn.py : simple discrete, deterministic Q-learning \n",
        "#\n",
        "# Requires: numpy, pandas, matplotlib\n",
        "#\n",
        "# Yoonsuck Choe\n",
        "# choe@tamu.edu\n",
        "#\n",
        "# 2021. 02. 17. (wed) 09:00:58 KST\n",
        "# 2021. 02. 18. (thu) 00:09:00 KST\n",
        "#\n",
        "# Getting started:\n",
        "# \n",
        "# - pick between \"console\" mode (for command line) or \"notebook\" mode (for colab, etc). \n",
        "#     See the config section.\n",
        "# \n",
        "#     mode  = \"console\"\n",
        "#\n",
        "# Suggested experiments:\n",
        "#\n",
        "# - change epsilon: \n",
        "#     0.1, 0.25, 0.5 (default), 0.8, 1.0 and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "#    \n",
        "#     ./qlearn.pl --epsilon=0.25 \n",
        "#\n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.epsilon = 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - change alpha: \n",
        "#     0.1, 0.25, 0.5, 0.8, 1.0 (default) and see how the Q diff plot looks like (how fast \n",
        "#     learning converges.\n",
        "# \n",
        "#     ./qlearn.pl --alpha=0.25 \n",
        "# \n",
        "#     or, for notebook mode\n",
        "# \n",
        "#     args.alpha= 0.25\n",
        "#     qlearn()\n",
        "# \n",
        "# - try a new grid world environment (change section below \"Environment set up\".\n",
        "#     search for \"modify\"\n",
        "#\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random \n",
        "import argparse, sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#--------------------\n",
        "# config (more config below : search for \"modify\" \n",
        "#\n",
        "# - for colab, etc, use the \"notebook\" mode\n",
        "#--------------------\n",
        "\n",
        "# mode=\"console\"\n",
        "mode=\"notebook\" \n",
        "\n",
        "#--------------------\n",
        "# console mode: process command line arguments\n",
        "#--------------------\n",
        "def parse_args():\n",
        "\n",
        "  cmd = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "  cmd.add_argument('--alpha', type=float, default=\"1.0\", help=\"mixing rate\")\n",
        "  cmd.add_argument('--gamma', type=float, default=\"0.9\", help=\"discount rate\")\n",
        "  cmd.add_argument('--epsilon', type=float, default=\"0.5\", help=\"greedy policy\")\n",
        "  cmd.add_argument('--num_iter', type=int, default=\"300\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--run_avg_rate', type=float, default=\"0.95\", help=\"number of iterations to run\")\n",
        "  cmd.add_argument('--display_flag', type=str, default=\"True\", help=\"display Q table after each iteration?\")\n",
        "\n",
        "  return cmd.parse_args()\n",
        "\n",
        "#--------------------\n",
        "# notebook mode: process command line arguments\n",
        "#--------------------\n",
        "class argclass:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.alpha = 1.0\n",
        "    self.gamma = 0.9\n",
        "    self.epsilon = 1.0\n",
        "    self.num_iter = 20000\n",
        "    self.run_avg_rate = 0.95\n",
        "    self.display_flag = \"True\"\n",
        "\n",
        "#--------------------\n",
        "# select mode \n",
        "#--------------------\n",
        "if (mode==\"console\"):\n",
        "\n",
        "  args = parse_args()\n",
        "\n",
        "elif (mode==\"notebook\"):\n",
        "\n",
        "  args = argclass()\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Invalid mode: check the config\")\n",
        "  exit()\n",
        "\n",
        "#--------------------\n",
        "# find sum of abs difference in the two table values\n",
        "#--------------------\n",
        "def df_diff(df1, df2):\n",
        "\n",
        "  d = df1-df2\n",
        "  return d.abs().to_numpy().sum() \n",
        "\n",
        "#--------------------\n",
        "# get optimal V from final Q\n",
        "#--------------------\n",
        "def get_optimalV(Q):\n",
        "  sz = len(Q)\n",
        "  V_optimal = np.zeros(sz)\n",
        "  \n",
        "  for i in range(sz):\n",
        "    V_optimal[i] = Q.iloc[i,:].max()\n",
        "  return V_optimal\n",
        "\n",
        "#------------------------------------\n",
        "# calculate the probabilistic outcome\n",
        "#------------------------------------\n",
        "def random_state(s, a, delta, num_actions):\n",
        "  \n",
        "  #calculate the p for s,a intended action\n",
        "  p=np.zeros(num_actions) \n",
        "  num_nonzero = (delta.iloc[s,:]>=0).sum()\n",
        "\n",
        "  for d in range(num_actions):\n",
        "    if delta.iloc[s,d]==-1: #illegal action\n",
        "      p[d]=0\n",
        "    else:\n",
        "      if d==a:\n",
        "        p[d]=0.7\n",
        "      else:\n",
        "        p[d]=0.3/(num_nonzero-1)\n",
        "  \n",
        "  #reject-accept action\n",
        "  while (True):\n",
        "    a_p = random.randint(0,num_actions-1) # generate random action\n",
        "    while delta.iloc[s,a_p] == -1: # illegal move\n",
        "      a_p = random.randint(0,num_actions-1)\n",
        "\n",
        "    r = random.random() \n",
        "\n",
        "    if (r <= p[a_p]):  \n",
        "      # accept event \"a\"!\n",
        "      a_actual = a_p\n",
        "      s_next_actual = delta.iloc[s,a_actual]\n",
        "\n",
        "      return s_next_actual, a_actual\n",
        "    else:\n",
        "      # reject event \"a\" and repeat\n",
        "      continue\n",
        "   \n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Environment set up : modify this part to change the environment\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "#--------------------\n",
        "# state index : modify\n",
        "#\n",
        "# layout =  (*) marks the goal. \n",
        "# \n",
        "# s0 s1 s2\n",
        "# s3 s4 s5 \n",
        "# s6 s7 (s8)\n",
        "# s9 s10 s11\n",
        "# \n",
        "#   * (s5,down), (s11, up), and (s7,right) has reward 100, all others are 0.\n",
        "#   * All actions in s8 lead back to s8, with reward 0.\n",
        "#\n",
        "#--------------------\n",
        "s_index = [\"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\"] \n",
        "\n",
        "#--------------------\n",
        "# state transition table : modify \n",
        "#--------------------\n",
        "delta = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        " \t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 1, 2, 3, 4, 8, 6, 7, 8]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 3, 4, 5, 6, 7, 8, 9,10, 8,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 1,-1, 3, 4,-1, 6, 8,-1, 9, 10]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 1, 2,-1, 4, 5,-1, 7, 8, 8,10,11,-1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "#--------------------\n",
        "# reward table : modify\n",
        "#--------------------\n",
        "reward = pd.DataFrame(\n",
        "\t{                 # for each s  0  1  2  3  4  5  6  7  8  9  10 11\n",
        "\t  \"up\"   : pd.Series(np.array([-1,-1,-1, 0, 0, 0, 0, 0, 0, 0, 0, 100]),index=s_index),\n",
        "\t  \"down\" : pd.Series(np.array([ 0, 0, 0, 0, 0,100,0, 0, 0,-1,-1,-1]),index=s_index),\n",
        "\t  \"left\" : pd.Series(np.array([-1, 0, 0,-1, 0, 0, -1,0, 0,-1, 0, 0]),index=s_index),\n",
        "\t  \"right\": pd.Series(np.array([ 0, 0,-1, 0, 0,-1, 0,100,0, 0, 0, -1]),index=s_index)\n",
        "\t}\n",
        ")\n",
        "\n",
        "print(\"\\n\\nDelta\")\n",
        "print(delta)\n",
        "\n",
        "print(\"\\n\\nReward\")\n",
        "print(reward)\n",
        "\n",
        "#--------------------\n",
        "# goal state : modify\n",
        "#--------------------\n",
        "goal = 8\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "#\n",
        "# Main algorithm : no need to modify much below here (for the deterministic case)\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def qlearn_nondeterministic(): \n",
        "\n",
        "  # extract number of states\n",
        "  num_states = len(s_index)\n",
        "  num_actions = 4\n",
        "  \n",
        "  # set up (s,a) visit count\n",
        "  visits = (delta>=0).astype(int)-1\n",
        "  #print(\"\\n\\nvisits:\")\n",
        "  #print(visits)\n",
        "\n",
        "  run_avg = 1\n",
        "  \n",
        "  #--------------------\n",
        "  # (1) Initialize Q table to zeros (-1 for invalid actions)\n",
        "  #\n",
        "  # - Reuse delta table to filter out invalid moves and set others to zero\n",
        "  #--------------------\n",
        " \n",
        "  Q=(delta>=0).astype(float)-1 \n",
        "\n",
        "  old_Q = Q.copy(deep=True) \n",
        "  \n",
        "  print(\"\\n\\nQ: initial\")\n",
        "  print(Q)\n",
        "  \n",
        "  # initialize the Sum_Ersa table\n",
        "  Sum_Ersa=(delta>=0).astype(float)-1 \n",
        "  print(\"\\n\\nSum_Ersa: initial\")\n",
        "  print(Sum_Ersa)  \n",
        "  #--------------------\n",
        "  # (2) Main loop\n",
        "  #--------------------\n",
        "  \n",
        "  d = np.zeros(args.num_iter)\n",
        "\n",
        "  n = 0 \n",
        "  while (run_avg > 0.01 or n < 50) and n<(args.num_iter):\n",
        "  #for n in range(args.num_iter):\n",
        "    \n",
        "    #----------\n",
        "    # 1. s : randomly select state   \n",
        "    #----------\n",
        "  \n",
        "    s = random.randint(0,num_states-1)\n",
        "  \n",
        "    while (s==goal): # avoid goal state\n",
        "      s = random.randint(0,num_states-1)\n",
        "      \n",
        "    #----------\n",
        "    # 2. a : choose action (epsilon greedy policy)\n",
        "    #----------\n",
        "  \n",
        "    if (random.random() < (1-args.epsilon)):\n",
        "  \n",
        "      # greedy action:\n",
        "      a = Q.iloc[s,:].argmax()\n",
        "  \n",
        "    else:\n",
        "  \n",
        "      # random action\n",
        "      a = random.randint(0,num_actions-1)\n",
        "  \n",
        "      while (delta.iloc[s,a]==-1): # avoid invalid action\n",
        "        a = random.randint(0,num_actions-1)\n",
        "  \n",
        "    #----------\n",
        "    # 3. train\n",
        "    #----------\n",
        "  \n",
        "    visits.iloc[s,a] = visits.iloc[s,a] + 1\n",
        "\n",
        "    alpha = 1.0/(1.0 + visits.iloc[s,a])\n",
        "    gamma = args.gamma\n",
        "  \n",
        "    # 3.1 find next state from (s,a) by rejection and accept\n",
        "    (s_next_actual, a_actual) = random_state(s, a, delta, num_actions)\n",
        "    r = reward.iloc[s,a_actual]\n",
        "    Sum_Ersa.iloc[s,a] += r\n",
        "\n",
        "    #s_next = delta.iloc[s,a]\n",
        "  \n",
        "    # 3.2 update Q\n",
        "  \n",
        "    # Equation is: Q(s,a) = (1-alpha) x Q(s,a) + alpha*( r(s,a) + gamma * max_a' Q(s',a') )\n",
        "    Q.iloc[s,a] = (1.0-alpha)*Q.iloc[s,a] + alpha*(r + gamma*Q.iloc[s_next_actual,:].max())\n",
        "  \n",
        "    # 3.3 compute running average of the sum of Q(n) minus Q(n-1)\n",
        "    if n == 0: \n",
        "      run_avg = 0\n",
        "\n",
        "    d[n] = args.run_avg_rate * run_avg + (1-args.run_avg_rate) * df_diff(Q,old_Q)\n",
        "    run_avg = d[n]\n",
        "    old_Q = Q.copy(deep=True)\n",
        "    n += 1 \n",
        "   \n",
        "    # 3.3 print current Q and running average of Q diff.\n",
        "  \n",
        "    if (args.display_flag == \"True\"):\n",
        "  \n",
        "      print(\"\\nQ : iter=\"+str(n-1))\n",
        "      print(Q)\n",
        "      print(\"diff = \"+str(d[n-1]))\n",
        "\n",
        "    #if (n>50  and run_avg < 0.01):\n",
        " \n",
        "    #    break\n",
        "\n",
        "  #--------------------\n",
        "  # (3) Print final Q table  and (s,a) visit count table\n",
        "  #--------------------\n",
        "  print(\"\\nFinal Q table\\n\")\n",
        "  print(Q)\n",
        "  \n",
        "  print(\"\\nFinal visit count table\\n\")\n",
        "  print(visits)\n",
        "\n",
        "  print(\"\\nFinal Sum_Ersa table\\n\")\n",
        "  print(Sum_Ersa)\n",
        "  \n",
        "  # calculate the Ersa table\n",
        "  Ersa = delta.copy(deep=True)\n",
        "  for ss in range(len(delta)):\n",
        "    for aa in range(len(delta.columns)):\n",
        "      if ss == goal: # set goal state Ersa to 0\n",
        "        Ersa.iloc[ss,aa] = 0\n",
        "      else:\n",
        "        if visits.iloc[ss,aa]==-1: # illeagal move has -1 ersa\n",
        "          Ersa.iloc[ss,aa] = -1\n",
        "        else:\n",
        "          Ersa.iloc[ss,aa] = Sum_Ersa.iloc[ss,aa]/visits.iloc[ss,aa]\n",
        "  \n",
        "  print(\"\\nErsa table\\n\")\n",
        "  print(Ersa)\n",
        "  #--------------------\n",
        "  # (4) Plot diff Q(n), Q(n-1) running average\n",
        "  #--------------------\n",
        "  plt.title(\"Difference in Q table values over time: Running average, rate=\"+str(args.run_avg_rate))\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Diff in Q table values\")\n",
        "  plt.plot(d)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"diff in Q reached below 0.01 at iteration = \"+str(n-1))\n",
        "\n",
        "  #--------------------\n",
        "  # (5) calculate V(s) based on final Q\n",
        "  #--------------------\n",
        "  V_optimal = get_optimalV(Q)\n",
        "  V_optimal = V_optimal.reshape(4,3)\n",
        "  print(\"\\nV_optimal is (in Figure 1 layout):\")\n",
        "  print(V_optimal)\n",
        "\n",
        "  return (Q, Ersa, gamma, num_actions)\n",
        "\n",
        "\n",
        "#-- end of qlearn() function def\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Run the qlearn main function\n",
        "#\n",
        "# - if you're using notebook mode, you can change the argument and rerun\n",
        "#   in the interactive session (create a new cell and put the following lines in it).\n",
        "#   \n",
        "#    args.epsilon = 0.8\n",
        "#    qlearn()\n",
        "#\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "args.display_flag = \"False\"  # Set this to \"True\" to see the changing Q table over time.\n",
        "args.epsilon = 1.0\n",
        "(Q, Ersa, gamma, num_actions) =qlearn_nondeterministic()\n",
        "\n",
        "# after you run it, check if your Delta (state transition table) and the Reward table are accurate, compared to Figure 1. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Delta\n",
            "     up  down  left  right\n",
            "s0   -1     3    -1      1\n",
            "s1   -1     4     0      2\n",
            "s2   -1     5     1     -1\n",
            "s3    0     6    -1      4\n",
            "s4    1     7     3      5\n",
            "s5    2     8     4     -1\n",
            "s6    3     9    -1      7\n",
            "s7    4    10     6      8\n",
            "s8    8     8     8      8\n",
            "s9    6    -1    -1     10\n",
            "s10   7    -1     9     11\n",
            "s11   8    -1    10     -1\n",
            "\n",
            "\n",
            "Reward\n",
            "      up  down  left  right\n",
            "s0    -1     0    -1      0\n",
            "s1    -1     0     0      0\n",
            "s2    -1     0     0     -1\n",
            "s3     0     0    -1      0\n",
            "s4     0     0     0      0\n",
            "s5     0   100     0     -1\n",
            "s6     0     0    -1      0\n",
            "s7     0     0     0    100\n",
            "s8     0     0     0      0\n",
            "s9     0    -1    -1      0\n",
            "s10    0    -1     0      0\n",
            "s11  100    -1     0     -1\n",
            "\n",
            "\n",
            "Q: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "\n",
            "Sum_Ersa: initial\n",
            "      up  down  left  right\n",
            "s0  -1.0   0.0  -1.0    0.0\n",
            "s1  -1.0   0.0   0.0    0.0\n",
            "s2  -1.0   0.0   0.0   -1.0\n",
            "s3   0.0   0.0  -1.0    0.0\n",
            "s4   0.0   0.0   0.0    0.0\n",
            "s5   0.0   0.0   0.0   -1.0\n",
            "s6   0.0   0.0  -1.0    0.0\n",
            "s7   0.0   0.0   0.0    0.0\n",
            "s8   0.0   0.0   0.0    0.0\n",
            "s9   0.0  -1.0  -1.0    0.0\n",
            "s10  0.0  -1.0   0.0    0.0\n",
            "s11  0.0  -1.0   0.0   -1.0\n",
            "\n",
            "Final Q table\n",
            "\n",
            "            up       down       left      right\n",
            "s0   -1.000000  45.009047  -1.000000  45.600779\n",
            "s1   -1.000000  55.700928  43.698898  52.846955\n",
            "s2   -1.000000  66.835231  54.442221  -1.000000\n",
            "s3   43.651295  52.728438  -1.000000  54.380871\n",
            "s4   52.518930  70.259005  51.838089  68.938673\n",
            "s5   63.504029  87.470739  64.083395  -1.000000\n",
            "s6   50.368310  52.878809  -1.000000  67.850724\n",
            "s7   63.725887  67.140945  60.170812  88.551735\n",
            "s8    0.000000   0.000000   0.000000   0.000000\n",
            "s9   58.155724  -1.000000  -1.000000  61.721953\n",
            "s10  72.833452  -1.000000  57.466564  75.638806\n",
            "s11  90.045263  -1.000000  74.475267  -1.000000\n",
            "\n",
            "Final visit count table\n",
            "\n",
            "      up  down  left  right\n",
            "s0    -1   702    -1    759\n",
            "s1    -1   532   506    463\n",
            "s2    -1   700   771     -1\n",
            "s3   504   474    -1    487\n",
            "s4   364   394   372    362\n",
            "s5   529   499   495     -1\n",
            "s6   500   458    -1    540\n",
            "s7   382   374   359    377\n",
            "s8     0     0     0      0\n",
            "s9   683    -1    -1    794\n",
            "s10  467    -1   519    498\n",
            "s11  790    -1   758     -1\n",
            "\n",
            "Final Sum_Ersa table\n",
            "\n",
            "          up     down     left    right\n",
            "s0      -1.0      0.0     -1.0      0.0\n",
            "s1      -1.0      0.0      0.0      0.0\n",
            "s2      -1.0      0.0      0.0     -1.0\n",
            "s3       0.0      0.0     -1.0      0.0\n",
            "s4       0.0      0.0      0.0      0.0\n",
            "s5    7900.0  35200.0   6200.0     -1.0\n",
            "s6       0.0      0.0     -1.0      0.0\n",
            "s7    3900.0   3500.0   3500.0  27000.0\n",
            "s8       0.0      0.0      0.0      0.0\n",
            "s9       0.0     -1.0     -1.0      0.0\n",
            "s10      0.0     -1.0      0.0      0.0\n",
            "s11  56300.0     -1.0  21300.0     -1.0\n",
            "\n",
            "Ersa table\n",
            "\n",
            "            up       down       left      right\n",
            "s0   -1.000000   0.000000  -1.000000   0.000000\n",
            "s1   -1.000000   0.000000   0.000000   0.000000\n",
            "s2   -1.000000   0.000000   0.000000  -1.000000\n",
            "s3    0.000000   0.000000  -1.000000   0.000000\n",
            "s4    0.000000   0.000000   0.000000   0.000000\n",
            "s5   14.933837  70.541082  12.525253  -1.000000\n",
            "s6    0.000000   0.000000  -1.000000   0.000000\n",
            "s7   10.209424   9.358289   9.749304  71.618037\n",
            "s8    0.000000   0.000000   0.000000   0.000000\n",
            "s9    0.000000  -1.000000  -1.000000   0.000000\n",
            "s10   0.000000  -1.000000   0.000000   0.000000\n",
            "s11  71.265823  -1.000000  28.100264  -1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEWCAYAAADCeVhIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwdVZn/8c/TS7qT0NmbLRACYRvAkSXsq4AsyibjiLu4RfyJI6gjiBv6w21cZlCcwaj8kFUUBRlFZBNkhwQhJIQ1JJC9E7JvvT2/P865SeVyt+6u7lvN/b5fr371vbWcem5V3XrqnDq3ytwdERGRLKmrdgAiIiL5lJxERCRzlJxERCRzlJxERCRzlJxERCRzlJxERCRzUklOZnalmX0t8f7TZrbEzNaa2VgzO9LMXozvz0pjmQPNzGaZ2XHVjqMYM7vUzK4rMX6umZ04wDFdbWaXDeQysyT/e1ELavEzS/8om5ziQW2Dma0xs5Vm9rCZnWdmm+d19/Pc/f/G6RuBHwMnufs27r4c+BZwRXx/a399mP7k7vu6+329mdeCf48JeoOZvWpm3zGzISXmuc/MPtHrgGVAmdm5ZvZgcljyezHAsRxnZt3xZHCNmT1vZh8diGVX6zPXqnInpX0s+/1mNs/M1pnZrWY2psS0p5vZzLjPPWxm+yTGnWtmXXFc7u+4csuvtOZ0uru3ALsA3wMuAn5VZNrtgGZgVmLYLnnvK2ZmDb2ZL2N+AkwBPgy0AKcCJwK/qWZQ0juDZJ9c6O7bACOAC4FfmNleVY4p87K0basZi5ntC/wc+BDhmL4e+O8i0+4BXA+cB4wC/he4LS/+R2LlJPd3X9kg3L3kHzAXODFv2CFAN7BffH81cBmwJ7AOcGAtcC/wcpx2QxzWBIwkJLdFwII4b30s61zgIeA/geVxXBPwQ+BVYAlwJTA0Tn8cMB/4ArA0lvnRRKxDgR8B84BVwIOJeQ8DHgZWAk8Dx1WyHoBLgd8C1wBrCIl3cpH59gC6gEPyhu8MbAKOLTDPt+M8G+M6uyIOvxx4DVgNTAeOTsxzKXAzcFOM6UngrUXirwMujttmefwsY4rEPxs4LfG+AWgDDozvfwcsjuv278C+iWmvBi5LbNcH88p2YPf4utQ2Hgf8KW6n14EHgLoi8R4BPBHjeQI4Ig4/B5iWN+2FwG0VLP84wj52Ufys1+aV809xW3XF7bWywOfPlfEltuynZwHvAF6In+uSRJkVb6MC6+A4YH7esKXAv+bHVWj6uK98EZgR1+NNQHOF37dCn7nYtGMJB7LVcVtdlr+P5H2GgvsacGgcXp+Y9l3AjHLrEphI2A8/Hrf93yvYr0vGDewN3BW36fPAeyrZbonvxGeAF4FXSn3vgVOAdqCDsN89HYcXPb72II7vADck3k+Ky2opMO35wJ/z9t0NwAnFvvuV/PXqmpO7P07Y6Y7OG/4CsG98O8rdj3f3SYSNfrqHjLmJsAN3ArsDBwAnAckmrEOBOYSM/W1CbW1PYP84z3jg64npt48bZDxhJ/uZmY2O434IHEQ4aI0hHBy6zWw88GfChhtD+DL+3sxaK1wNZxBqPqOA24Arikx3AuGL/3hyoLu/BjwaPzt5475COACfH9fZ+XHUE3EdjAFuAH5nZs2JWc8kfKly42+Nzaz5Pks4MB4L7AisAH5WJP4bgfcl3p8MLHP3J+P7vxAS8LaEhHh9kXLKKbWNv0DY31oJ+8QlhC/xVmKzw58JNdWxhOblP5tZ7mCyVzzLy3k/YT2VWz6EfWwMoRVgSnK57j6bcNaYOzscVeQzbk9oVciV/Qvgg4T982jga2a2a5y25DYysxlm9v4iy0mukzozO4OQ4F8qN33CewgHv12BfyYcYJKfo9j3LV+paX9GOJndHvhI/Cul4L7m7o/Fco5PTJvctpXs78cSTjJOLrWscnGb2XBCYrohzvte4L+TzVwVOItwDMzNU/B77+53EJLITXG/e2uc/mqKHF/N7Kh4eabY31GxjH0JJ+wAuPvLhOS0Z5GYLe+1Afslhh1gZsvM7AUz+1pFtcIKMuhc8mpOcfijwFcKnC1NJBw4GgqVQTi4bCKelcZh7wP+lsiyrybGGWFHmJQYdjhbziqOI2Tp5PKWEmpFuQz+1gLxX8Qbz4D/Cnyk3Hog1FLuTozbB9hQZL6vAo8WGfcbYGqRcfcBnyizbVbkPluM6dHEuDrCmdPRBeKfTTyrie93IJx9NRRYxu6Emtiw+P564OtF4hkVt/3IAvvFuRSpOVWwjb8F/JFYyyqxPj4EPJ437BHg3Pj6ulzshAPPGmBYhftYO7H2UGTZhT5f8vPn9tNcC0FL/PyHJqafDpzV021UIJbjCK0VKwnftS7ggkJxJabPrzl9MPH+P4Ary33fSnzmQt/N+vh59kqMK1lzKrOvXQZclVi364Bdyq1LthyvdqtkWeXiJtTQH8ib/+fANyr8XA4c38Pv/XWJcSWPr5X+AfcA5+UNW0CB1iVCTXFd3N5DgK/F/e/LcfxuhJOcOuAtwLO5caX++tJbbzyh2tpTuwCNwKJctiZsvG0T07yWeN1KOIBMT0x/Rxyes9zdOxPv1wPbEM4WmwnV+UJx/GvyrAE4irDjVmJx3vKai5wNLCtR5g5xfEXM7ItmNtvMVsV4RxI+Y87m9ebu3YTaxo4FitoFuCXxuWcTDmDb5U/o7i/F8aeb2TBCjfGGGE+9mX3PzF42s9WEgxp5MVWi3Db+AeGs/04zm2NmFxcpZ0dC823SPMK+Sow7Vwt8P3Cru6+vYPkAbe6+sYefK99yd++KrzfE/0sS4zcQ9lvowTYqYqGHGtwIQk3y+DLT58vfv7dJvC/2fSuk2LSthOSQ/K4nX2+lgn3tBuBsM2sCzgaedPfcvlDJuty87DLLKhf3LsCheceVDxBqWZXaaj1U8L1PquT4Wom1hH0naQThhG4r7v4cofZ4BeGEeBwhAc2P4+e4+yvu3u3uzxBONt9dLoBeXXAzs4MJX/gHy01bwGuEzD4ub6dNSjbZLCN8afd19wU9XNYywrWASSSqqIk4rnX3T/awzJ66l1CtP8QTTXtmtjPhDPLbRebbqtnKzI4mNEmeAMxy924zW8HW1emdE9PXATsBCwuU/RrwMXd/qMLPkGvaqwOejQkLwgH+TELnjrmEL01+TDnrCAkgF1/yy1pyG7v7GkLT3hfMbD/gXjN7wt3vyZt0IeHLmTSBkGggNLe0mtn+8fNcWMnyc2EUGV7p+J7q6TYqyN03mdlFwPNmdpaH3rJbbQt6duBMSxuh6WknwjU3SOy/BZTc19z9WTObR+hslGzSgxLr0swmxpfJ7VdqWeXifg24393fXuKzlLM5lgq+9/n7XcnjayzvLyWWfaq7P0C4jp5rJsTMdiNcl32h0EzufjPhmjdmNorQhPtEic9X6BixlR7VnMxshJmdRmiOui5mwR5x90XAncCPYnl1ZjbJzI4tMn03oW3+P81s2xjHeDM7udD0Bea9Cvixme0Yz4gOj2dX1xFqAyfH4c0WuuDu1NPPVCaGFwgX1683s8PisvYFfk/ojHF3kVmXEKrDOS2EL0Ub0GBmX+eNZzYHmdnZsQZ3AWEnfbRA2VcC3zazXQDMrNXMzizxMX5DaLf+NFt/6VviMpYTDnbfKVHG08C+ZrZ/vE52aW5EuW1sZqeZ2e5mZoQL1F2EZoN8twN7WugC22Bm5xCaXP8Ul9NBuCb3A0L7/V2VLL9CS4CdrMTPA3qop9uoKHdvJ3QKyl1Dewp4h5mNiScJF6QRcA9j6gL+AFxqZsPMbG9Cb9ZiKtnXbgA+BxxD2M45PV2XRZdVQdx/IuyDHzKzxvh3sJn9U1z2uWY2t8SyC8VS6nu/BJgYT0bLHl/d/QHfutdc/t8DsdzrCcfHoy1cR/sW8Id4ovgGZnZQPLa1AlMJHY2ei+NONbPt4uu9Cc1+fyz3wStNTv9rZmsIWfkrhAvNffndxIcJbZPPEs5IbqZ0c9pFhGadR2M1+26g0m6xXwSeIWTx14HvE3p6vUY4O7qEsOFfA/6d/rlrxvnALwkJcT0wk9DcdFY8MBZyOfBuM1thZj8hXA+7g3DmMo9QI8xvBvkjoc17BeH6y9nxgFyo7NsIzWRrCAns0GLBxx3+EUKnkpsSo66JsSwgbMtCiTBXxguEHfxuQk+k/Fp3qW28R3y/Nsbx3+7+twLLWA6cRqhlLSeccZ7m7smm0xsIZ8S/yzuz7Ms+BqGGPAtYbGYVN9WWUHIbWfhR+Ad6UN5VwAQzOx24lnCyMJdwILupxHz96XxCrWRxjOlGQlIopJJ97UZCx4Z787Z5j/b3CpZVNO548D6J0BFiYZzm+4RaB4RaVk9qw+W+97kkvNzMcp2Uenp8fQN3n0Xo5HM94TphC/B/cuPN7C9mdklilssJ1zifj8tMtkidAMwws3WEE8g/UPpENiwjXrCSAWRm3yR0dT3G3VdWOx6RLDCz7wPbu3u5XnuZ0pO4zexO4HMeenhKCUpOVWJm5wMveegOKlJzYhPPEELLxsGEs+pPeMbvIjNY4x5sMvNr6Frj7sV+FyVSK1oITWI7Eq6d/IgKrkVkwGCNe1BRzUlERDJHj8wQEZHMGXTNeuPGjfOJEydWOwwRkUFl+vTpy9y90tuzVd2gS04TJ05k2rRp1Q5DRGRQiT9SHjTUrCciIpmj5CQiIpmj5CQiIpmj5CQiIpmj5CQiIpmj5CQiIpmj5CQiIplTc8npr7MWs3RNXx9oKiIi/ammktOmzi4+de10PvCLx6odioiIlJCJ5GRmF8aHp800sxvjk1JTl7vH7auvr++P4kVEJCVVT05mNh74N2Cyu+8H1BOeIikiIjWq6skpagCGmlkDMIzweGMREalRVU9O7r4A+CHwKrAIWOXudyanMbMpZjbNzKa1tbX1fZl9LkFERPpT1ZOTmY0GzgR2JTxZcriZfTA5jbtPdffJ7j65tbX3d3zPXXOyXpcgIiIDoerJCTgReMXd29y9A/gDcER/LMhVZxIRGRSykJxeBQ4zs2FmZsAJwOz+WJCeSC8iMjhUPTm5+2PAzcCTwDOEmKb2y7L6o1AREUldJp6E6+7fAL4xAMsBwHTRSUQk06pecxpIqjmJiAwOtZWclJ1ERAaFmkpOuaqTkpSISLbVVnISEZFBoaaSk37nJCIyONRWclJuEhEZFGorOVU7ABERqUhtJSdVnUREBoXaSk7VDkBERCpSW8lJ2UlEZFCoreSkupOIyKBQU8np67fOqnYIIiJSgZpKTnfMWlztEEREpAI1lZxERGRwUHISEZHMqXpyMrO9zOypxN9qM7ugP5e5qbO7P4sXEZE+qvrDBt39eWB/ADOrBxYAt1Q1KBERqaqq15zynAC87O7zqh2IiIhUT9aS03uBG6sdhIiIVFdmkpOZDQHOAH5XYNwUM5tmZtPa2toGPjgRERlQmUlOwKnAk+6+JH+Eu09198nuPrm1tbUKoYmIyEDKUnJ6H2rSExERMpKczGw48HbgD9WORUREqq/qXckB3H0dMLbacYiISDZkouYkIiKSpOQkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZo+QkIiKZk1pyMrN/NbOW+PqrZvYHMzswrfJFRKR2pFlz+pq7rzGzo4ATgV8B/1PJjGY2ysxuNrPnzGy2mR2eYlwiIjLIpJmcuuL/dwJT3f3PwJAK570cuMPd9wbeCsxOMS4RERlk0kxOC8zs58A5wO1m1lRJ+WY2EjiGUNPC3dvdfWWKcYmIyCCTZnJ6D/BX4OSYXMYA/17BfLsCbcD/M7N/mNkvzWx4cgIzm2Jm08xsWltbW4ohi4hIFqWWnNx9PbAUOCoO6gRerGDWBuBA4H/c/QBgHXBxXtlT3X2yu09ubW1NK2QREcmoNHvrfQO4CPhyHNQIXFfBrPOB+e7+WHx/MyFZiYhIjUqzWe9dwBmEmg/uvhBoKTeTuy8GXjOzveKgE4BnU4zrDSa1Di8/kYiIVE2ayand3R1wgPzrRmV8FrjezGYA+wPfSTGuzY6YNBaA1Rs7+6N4ERFJSUOKZf029tYbZWafBD4G/KKSGd39KWByirGU1LZm00AtSkREeiG15OTuPzSztwOrgb2Ar7v7XWmVn4aHX15e7RBERKQCadaciMkoUwlJREQGn9SSk5mtIV5vItwZohFY5+4j0lqGiIjUhjSb9Tb3zDMzA84EDkurfBERqR398sgMD24FTu6P8kVE5M0tzWa9sxNv6wi97zamVb6IiNSONDtEnJ543QnMJTTtiYiI9Eia15w+mlZZIiJS2/qcnMzsp2zppfcG7v5vfV2GiIjUljRqTtNSKENERGSzPicnd/91GoGIiIjkpNlbr5XwyIx9gObccHc/Pq1liIhIbUjzd07XA7MJT7b9JqG33hMpli8iIjUizeQ01t1/BXS4+/3u/jEgk7WmHUc2l59IRESqJs3fOXXE/4vM7J3AQmBMiuWnprto30IREcmCNJPTZWY2EvgC8FNgBHBhJTOa2VxgDdAFdLp7vz7bqduVnUREsizN5PSYu68CVgFv68X8b3P3ZSnGU5RSk4hItqV5zekhM7vTzD5uZqNTLDd1rpqTiEimpZac3H1P4KvAvsB0M/uTmX2w0tmBO81suplNyR9pZlPMbJqZTWtra+ttfJtf65qTiEi2pfrIDHd/3N0/DxwCvA5U+gPdo9z9QOBU4DNmdkxeuVPdfbK7T25tbe1znLrmJCKSbaklJzMbYWYfMbO/AA8DiwhJqix3XxD/LwVuqXS+3lq5voNNnV39uQgREemDNGtOTwP7A99y9z3d/SJ3n15uJjMbbmYtudfAScDMFOMCIL+y9Nic19NehIiIpCTN3nq7ee96GmwH3BKe7E4DcIO735FiXAWpYU9EJLvSfJ5Tr4737j4HeGtacVRK151ERLIr1Q4Rg4pyk4hIZtVMcsrPRa7sJCKSWWn21tvTzO4xs5nx/T+b2VfTKj9tatUTEcmuNGtOvwC+TLwBrLvPAN6bYvmpUnISEcmuNJPTMHd/PG9YZ4rl90l+fw11iBARya40k9MyM5tEvLxjZu8m/BA3k9q7uqsdgoiIFJHm75w+A0wF9jazBcArQKX31htw69t1hwgRkaxK83dOc4AT410e6tx9TVpl94fGeqt2CCIiUkSfk5OZfb7IcADc/cd9XUYa8q8wqVVPRCS70qg5taRQxoDr1nMzREQyq8/Jyd2/mUYgA62jW1UnEZGsSvNHuLuZ2f+aWZuZLTWzP5rZbmmVn7arH5pb7RBERKSINLuS3wD8FtgB2BH4HXBjiuX3Sf7Pmpas3lidQEREpKy0f4R7rbt3xr/rgOYUy0/Vuw4YX+0QRESkiDR6642JL/9iZhcDvyF0jjsHuL2v5feX1pamaocgIiJFpNFbbzohGeV+OPSpxDgn3G+vJDOrB6YBC9z9tBRieoP8u5CrK7mISHal0Vtv1xTi+BwwGxiRQlkVufbRuXzuxD0GanEiItIDad6+CDPbD9iHxLUmd7+mzDw7Ae8Evg0U/EFvf1i2tn2gFiUiIj2UWnIys28AxxGS0+3AqcCDQMnkBPwX8CVK/JjXzKYAUwAmTJiQQrQiIpJlafbWezdwArDY3T8KvBUYWWoGMzsNWOru00tN5+5T3X2yu09ubW3tVXC5ruQTxgzr1fwiIjJw0kxOG9y9G+g0sxHAUmDnMvMcCZxhZnMJvfyON7PrUozpDQ7ddUz5iUREpKrSTE7TzGwU4Ym404EngUdKzeDuX3b3ndx9IuGpufe6e78+ZqPOdDdyEZGsS/ORGf8nvrzSzO4ARsRHtWdKXZ2Sk4hI1qV5b717cq/dfa67z0gOK8fd7+uv3zgl1adZVxQRkX6Rxh0imoFhwDgzG82WH+OOADJ3jyA164mIZF8azXqfAi4g3Ox1OluS02rgihTKT5WSk4hI9qVxh4jLgcvN7LPu/tMUYuoXua7kydzU3e26BiUikkGpXYHJcmJKqk9kp67852iIiEgm1Fz3gGRNqUuPahcRyaSaS05bNeup5iQikkmp/M7JzIYCHyDcVw/C4y9udvfM3F0198iMZLNep2pOIiKZ1Oeak5m9BXgWOBqYG/9OBh4ys1Fmdllfl5Gm+kSzXreSk4hIJqVRc/oJMMXd70oONLMTgZnArBSWkRozXXMSEcm6NK457ZCfmADc/W6gA3hXCsvos9zlpWTPcfXWExHJpjSSU52ZNeUPjHeO6HD39SksIzX1qjmJiGReGsnpGuD3ZrZLboCZTQR+C1ybQvmpUldyEZHsS+MOEZeZ2fnAA2aWe5LfOuCHWfxh7tZ3iKheHCIiUlwqXcnd/QrgCjNrie/XpFFumnJ1pK27kis7iYhkUao/wnX3NVlMTEnJG7/eNO21KkYiIiLFVP0OEWbWbGaPm9nTZjbLzL45UMt+duHqgVqUiIj0QGpPwu2DTcDx7r7WzBqBB83sL+7+aJoL8QLdxh94cVmaixARkZSkmpzM7AhgYrJcd7+m1Dwessba+LYx/vVbNzo9zklEJPtSS05mdi0wCXgK6IqDndDVvNy89YQHFe4O/MzdH8sbPwWYAjBhwoS0QgZg7aZOtmnKQgVSRERy0jwqTwb28ULtZ2W4exewv5mNAm4xs/3cfWZi/FRgKsDkyZNTrVXpzuQiItmTZoeImcD2fSnA3VcCfwNOSSWiZNlFl5n2kkREpK/SrDmNA541s8cJnRwAcPczSs1kZq2E2xytjI/eeDvw/RTjKk3JSUQkc9JMTpf2cr4dgF/H6051wG/d/U+pRVWGmvVERLInteTk7vf3cr4ZwAFpxVF8OUWG9/eCRUSkx9J42OCD8f8aM1ud+FtjZpn7lavl9SWfvyJTN00XERFSSE7uflT83+LuIxJ/Le4+ou8h9q8zrnio2iGIiEieqt++SEREJF/tJKfExaU7Lji6enGIiEhZaVxzesNTcLPMgDHDhlQ7DBERKSGNmtMjsPn2RZnVtjb89Gr1xo6QoUREJLPS6Eo+xMzeDxxhZmfnj3T3P6SwjD6bMX8lAPOWr8eUnUREMi2N5HQe8AFgFHB63jgHMpGccj3I3V13JhcRybg0ktMO7v5pM/tHvEFrJuVqS/rRrYhI9qVxzenL8f95KZTVb3K1pW6HUUMbtxq3qbOrwBwiIlItadSclpvZncCuZnZb/shyN34dKLk7Q3S701C/dU5evaGT1pb6aoQlIiIFpJGc3gkcCFwL/CiF8vrF5stMatcTEcm8Picnd28HHjWzI9y9LYWY+kWd5a45hez02eN356f3vgTo0e0iIlnT5+RkZv/l7hcAV5nZG+olWWnWq8tdc+oO//fdcWT1ghERkZLSaNbL/fj2hymU1W+2dIgI+fP5xWuqGI2IiJSSRrPe9Pj//vhUW3rSvGdmOwPXANsRrghNdffL+xpXgSUBWy45TZv3+uYxeuCgiEi2pHLjVzO71MyWAc8DL5hZm5l9vcLZO4EvuPs+wGHAZ8xsnzTiSqrb/CPc8L8x0WOvq1vJSUQkS9K48evngSOBg919jLuPBg4FjjSzC8vN7+6L3P3J+HoNMBsY39e4CsSZWx4ADXVbekF0dik5iYhkSRo1pw8B73P3V3ID3H0O8EHgwz0pyMwmEh7Z/lgKcW1ddvyfS0MN9VuSk2pOIiLZkkZyanT3ZfkD43WnxgLTF2Rm2wC/By5w99V546aY2TQzm9bW1rve6nV1m+MCYOzwLU/66FRyEhHJlDSSU3svx21mZo2ExHR9obuYu/tUd5/s7pNbW1t7FeSWO0SE9x88bJfN41RzEhHJljS6kr/VzFYXGG5Ac7mZLWSNXwGz3f3HKcRTeDnxf65nXn3ymlPux08iIpIJaXQl7+tN6Y4kXLd6xsyeisMucffb+1juVizvNhDNjeqtJyKSVWnUnPrE3R9kAJ5Nm9+VfGjjlpyqa04iItmSyu+cBoO6xF3JARrqVHMSEcmqmklOm7uSxzyU7Equ3zmJiGRLzSSnXHbK3ZVcv3MSEcmumklOdXldyRsTzXrqrSciki01k5y2NOuF7FRXp5qTiEhW1U5y2nxvvTeOU289EZFsqZnktLkreYFx3719Nps6uwY0HhERKa5mkpPldSVPmrt8PXt99Q5mLyp0owsRERloNZScwv9SLXhPvrpiYIIREZGSaic55V4kak6Xv3f/rabp6FSvPRGRLKiZ5JTrSp6sOO02bputplG/CBGRbKiZ5JR7LHvynnpv2WnkVtMUuh4lIiIDr+o3fh0o/7RDCxedsjf/cmDxJ8C3rd00gBGJiEgxNVNzMjM+fdwkth1R/BFTP79/zgBGJCIixdRMchIRkcFDyUlERDKn6snJzK4ys6VmNrMay//u2W+pxmJFRKSEqicn4GrglGot/D2Td67WokVEpIiqJyd3/zvwerWWX1/X70+IFxGRHqp6cqqEmU0xs2lmNq2tra3a4YiISD8bFMnJ3ae6+2R3n9za2lrtcEREpJ8NiuTU3/7rnC332OvudqbNfX3zQwlFRGTgKTkBZx0wnoN2GQ3AbU8v5N1XPsLvps+vclQiIrWr6snJzG4EHgH2MrP5ZvbxasRx8r7bAfDnZxYB8KWbZ1QjDBERIQP31nP391U7BoCmhnBD2LueXbJ5WHtnN431tvlBhSIiMjCqXnPKiifmvrE3+5xla9n1y7dz6z8WVCEiEZHapeQUPf7KG5PTM/NXAXDto/MGOhwRkZqm5BQdvccbu6j/e7zuNH2eHt8uIjKQlJyicvfYm7tsHb98YA6dXXqUu4hIf1NyioY01HHlBw8qOv64H97HZX+ezY1PvEaXnucuItKvlJwSTtlve+Z+750lp/narTOZdMntAxSRiEhtUnIq4ObzDi87zbzl67hz1mLmLls3ABGJiNSWqv/OKYsmTxxTdppjf3Df5tevfPcd3D17Kcfvva3uci4ikgLVnMoYt01T2WkO/vbdfPKaafzqwTkDEJGIyJufklMRR+0+DoAHvvQ2vvOu0j35lq1tB+CaRybxolYAAA3bSURBVPR7KBGRNNhgu/v25MmTfdq0af2+nK5up6vbGdJQh7sz5drpPPzSMta1d5Wd984Lj2Hn0cNYuGoDk1q36fdYRUTKMbPp7j652nFUSsmpB7q6nZueeI1Lbnmm7LRvGT+SZxas4rtnv4X3HTJh8/Dc+tb9+kRkICk59bNqJqeciRf/GQgdIe59bikf/3X5eHYaPZTvnv0WPvSrxwG444Kjad2miYMuuxugbBd2EZG+UHLqZ1lITp1d3XR2O82N4U7m85avY+TQRvb/1l29LvPI3ceybUszJ+2zHcfu1cqqDR1sP6KZji5nfXsnw4Y0MKRBlwhFpHeUnPpZFpJTOZff/SL/efcL/VL2zz90EFfe/zL/eHVlwfHXffxQ2tZuZO2mLt5/yARWrG/nntlL2Hn0MO5/oY1PHTuJ0cMaWdfexTZNDbi7mhhFaoCSU2+CMDsFuByoB37p7t8rNu1gSE457s5DLy1n+5HNnPjj+zcP/9Nnj+K0nz5Yxch655J37M13bn8OgE8dsxsjhjbyg78+z17btfD8kjUcs2crf3+hjZvPO5xPXjONnccMY8b8Vdz9+WPZbkQTGzu6+dvzS7l39lI+87bdmbVwFcObGvjJPS8yZvgQfnzO/uw4shnYck3u1eXrmbNsLUfuPo56M+pS/B3Z+vZOmhvq31BmsjNMd7e/YXyhYSJZp+TU0wDM6oEXgLcD84EngPe5+7OFph9MyamUrm7HgLo6457ZS+h2+M7ts3mlwB0nfv/pw/ntE/O5adprAx+oVGy3ccOZk7f93rZXK82N9Tz00jJWb+wEYNuWJlZu6OCUfbdn1sLwWBYHRg8bwvR5K9hl7DAa6oyX20JZO48Zymuvb6CpoY7DJ41lh5HNjGhuZMb8VWzs7GKXMcO4feZixgwbwn7jRzKiuYEXl65l9PAhTBw7jGP2aOXGx1/lnueWAnDghFFMnjgGA1pbmth2RDM/v/9lZi1czaTW4Zz2zzvS0tzAtLkrOOeQnbn6obls6OjibXtty9xl69hr+xZaW5qYtXA1bxk/krnL19Hd7TQ11vH6ug4O220M3/rTs8xpW8dFp+xNa0sTzy1azbiWJv7+QhutLU0csPMohjU1MHHscO6YuZi7Zy/hY0dO5JkFqxk/eigjmhvYd8eRbOzoorG+jo0dXYwY2sioYY0sXb2J19e309EZbsL8zIJVHLX7ONZ3dLFdSxP77DiClubGgdnog4iSU08DMDscuNTdT47vvwzg7t8tNP2bJTn1l7WbOmmsN5oa6rn3uSW0dzqH7jqGVRs6mDhuODMXrOLaR+bxcttaps1bwdF7jOOYPVr59u2ztyrn3CMmcvXDc6vzIUT6aPdtt+HNWLc964DxfOZtu/dqXiWnngZg9m7gFHf/RHz/IeBQdz8/Mc0UYArAhAkTDpo3Tz92fbPr7nYcyt4OKnfNrKOrm3ozkpfPzIz2zu7NHUly0+b2+W5n8wHMDNa3dzG8qfAdvbq6nY6ubjq6umlpbmRjRxdm8NyiNew4aihNjXV0dHbT7aE20t7ZzYaOLpas3siry9dzwIRRtDQ30tXtrNzQzl+eWczYbYYwZvgQtm1pZmNHF0OH1DNx7HAWrNzAjPkrOXbPVto7u1m+rp1hQ+pZvGojo4YNYUNHF8vXbqKxvo7WliaWrtnE8CH1dHY7MxesYlLrNuw7fgTPLVpDfZ0xvKkBgxi/s2J9O6OGNTJ62BAa6+vo9tCMuWDFBnYY1cz69i7mLlvHxs5udhjRzPYjm1m8aiOvvr6eY/dqZUN7F/OWr2fhyg2MHz2UOjPq64zOrm7q6oymhjra1mxi3DZNOM7IoY08HJu3V6xvZ9WGDt6+z/Y8/dpKdmsdzquvr2dDexcTxw5nxfp2NnZ0sWjVRiaOHc6mzi7q6oznFq1h8sTRAKze0MGIoY0xbliwYgPbj2xifXsXmzq7mbVwNV3db85H2xy357a85+CdezWvklNPA6ggOSWp5iQi0nODLTlloW/yAiB5KrBTHCYiIjUqC8npCWAPM9vVzIYA7wVuq3JMIiJSRVV/ZIa7d5rZ+cBfCV3Jr3L3WVUOS0REqqjqyQnA3W8H9HhZEREBstGsJyIishUlJxERyRwlJxERyRwlJxERyZyq/wi3p8ysDejtLSLGActSDCdNWY1NcfWM4uoZxdUzfYlrF3dvTTOY/jToklNfmNm0rP5COquxKa6eUVw9o7h6Jqtx9Qc164mISOYoOYmISObUWnKaWu0ASshqbIqrZxRXzyiunslqXKmrqWtOIiIyONRazUlERAYBJScREcmcmklOZnaKmT1vZi+Z2cUDsLydzexvZvasmc0ys8/F4Zea2QIzeyr+vSMxz5djfM+b2cn9FbuZzTWzZ+Lyp8VhY8zsLjN7Mf4fHYebmf0kLnuGmR2YKOcjcfoXzewjfYxpr8Q6ecrMVpvZBdVYX2Z2lZktNbOZiWGprR8zOyiu/5fivBU9UbxIXD8ws+fism8xs1Fx+EQz25BYb1eWW36xz9jLuFLbbhYep/NYHH6ThUfr9DaumxIxzTWzp6qwvoodG6q+j2WKu7/p/wiP4ngZ2A0YAjwN7NPPy9wBODC+bgFeAPYBLgW+WGD6fWJcTcCuMd76/ogdmAuMyxv2H8DF8fXFwPfj63cAfyE80fww4LE4fAwwJ/4fHV+PTnF7LQZ2qcb6Ao4BDgRm9sf6AR6P01qc99Q+xHUS0BBffz8R18TkdHnlFFx+sc/Yy7hS227Ab4H3xtdXAp/ubVx5438EfL0K66vYsaHq+1iW/mql5nQI8JK7z3H3duA3wJn9uUB3X+TuT8bXa4DZwPgSs5wJ/MbdN7n7K8BLMe6Biv1M4Nfx9a+BsxLDr/HgUWCUme0AnAzc5e6vu/sK4C7glJRiOQF42d1L3Qmk39aXu/8deL3A8vq8fuK4Ee7+qIejyDWJsnocl7vf6e6d8e2jhCdJF1Vm+cU+Y4/jKqFH2y2e8R8P3JxmXLHc9wA3liqjn9ZXsWND1fexLKmV5DQeeC3xfj6lE0WqzGwicADwWBx0fqyeX5VoCigWY3/E7sCdZjbdzKbEYdu5+6L4ejGwXRXiynkvWx80qr2+IL31Mz6+Tjs+gI8RzpJzdjWzf5jZ/WZ2dCLeYssv9hl7K43tNhZYmUjAaa2vo4El7v5iYtiAr6+8Y8Ng2McGTK0kp6oxs22A3wMXuPtq4H+AScD+wCJC08JAO8rdDwROBT5jZsckR8azrar8xiBeTzgD+F0clIX1tZVqrp9izOwrQCdwfRy0CJjg7gcAnwduMLMRlZaXwmfM3HbL8z62PgEa8PVV4NjQp/LebGolOS0Adk683ykO61dm1kjY+a539z8AuPsSd+9y927gF4TmjFIxph67uy+I/5cCt8QYlsTmgFxTxtKBjis6FXjS3ZfEGKu+vqK01s8Ctm5663N8ZnYucBrwgXhQIzabLY+vpxOu5+xZZvnFPmOPpbjdlhOasRryhvdaLOts4KZEvAO6vgodG0qUV/V9rBpqJTk9AewRe/0MITQb3dafC4xt2r8CZrv7jxPDd0hM9i4g15PoNuC9ZtZkZrsCexAuaqYau5kNN7OW3GvCBfWZscxcb5+PAH9MxPXh2GPoMGBVbHr4K3CSmY2OTTYnxWF9tdUZbbXXV0Iq6yeOW21mh8V95MOJsnrMzE4BvgSc4e7rE8Nbzaw+vt6NsH7mlFl+sc/Ym7hS2W4x2f4NeHcacUUnAs+5++amr4FcX8WODSXKq+o+VjU96T0xmP8IPV5eIJwRfWUAlncUoVo+A3gq/r0DuBZ4Jg6/DdghMc9XYnzPk+hdk2bshN5QT8e/WbnyCG379wAvAncDY+JwA34Wl/0MMDlR1scIF7RfAj6awjobTjhTHpkYNuDri5AcFwEdhPb6j6e5foDJhIP1y8AVxDu19DKulwjXHXL72JVx2n+J2/cp4Eng9HLLL/YZexlXatst7rOPx8/6O6Cpt3HF4VcD5+VNO5Drq9ixoer7WJb+dPsiERHJnFpp1hMRkUFEyUlERDJHyUlERDJHyUlERDJHyUlERDJHyUlqmpmtjf8nmtn7Uy77krz3D6dZvsibmZKTSDAR6FFySty1oJitkpO7H9HDmERqlpKTSPA94GgLz/K50MzqLTwr6Yl489JPAZjZcWb2gJndBjwbh90ab6I7y+KNdM3se8DQWN71cViulmax7JkWnrlzTqLs+8zsZgvPaLo+/sJfpOaUO/MTqRUXE54/dBpATDKr3P1gM2sCHjKzO+O0BwL7eXjkA8DH3P11MxsKPGFmv3f3i83sfHffv8CyzibcEPWtwLg4z9/juAOAfYGFwEPAkcCD6X9ckWxTzUmksJMI9zN7ivA4g7GE+60BPJ5ITAD/ZmZPE56ntHNiumKOAm70cGPUJcD9wMGJsud7uGHqU4TmRpGao5qTSGEGfNbdt7qZrZkdB6zLe38icLi7rzez+4DmPix3U+J1F/qOSo1SzUkkWEN4ZHbOX4FPx0cbYGZ7xru45xsJrIiJaW/Co7FzOnLz53kAOCde12olPE788VQ+hcibhM7KRIIZQFdsnrsauJzQpPZk7JTQRuFHXd8BnGdmswl32X40MW4qMMPMnnT3DySG3wIcTrgzvANfcvfFMbmJCOiu5CIikj1q1hMRkcxRchIRkcxRchIRkcxRchIRkcxRchIRkcxRchIRkcxRchIRkcz5/04etyr2gDnXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "diff in Q reached below 0.01 at iteration = 16411\n",
            "\n",
            "V_optimal is (in Figure 1 layout):\n",
            "[[45.60077861 55.70092793 66.83523115]\n",
            " [54.38087051 70.25900548 87.47073937]\n",
            " [67.85072388 88.55173504  0.        ]\n",
            " [61.72195338 75.63880595 90.04526256]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XV6wHrGv2e4"
      },
      "source": [
        "**Problem 9 (Program: 10 points)**\n",
        "\n",
        "For all $(s,a)$, verify if the following equation in slide04-rl.pdf page 34 is approximately accurate. \n",
        "\n",
        "\n",
        "> $ Q(s,a) =      E[r(s,a)] + \\gamma \\sum_{s'} P(s'|s,a) \\max_{a'} Q(s',a') $\n",
        "\n",
        "For this, on the left hand side, you will simply look up your $Q$ table. The $P(s'|s,a)$ are defined in the beginning of Section II: It is 0.70 for the intended direction, and 0.1, 0.15, or 0.3 for unintended directions, depending on the number of legal moves from $s$.\n",
        "\n",
        "```\n",
        "Q.iloc[s,a]\n",
        "```\n",
        "\n",
        "On the right hand side, you will compute \n",
        "\n",
        "```\n",
        "Ersa.iloc[s,a] + args.gamma * ( .... + p * Q.iloc[s_prime,:].max() + .... )    \n",
        "\n",
        "# p = 0.7, if s_prime was in the intended direction, and \n",
        "# p = 0.1 or 0.15 or 0.3, for unintended direction, depending on the number of\n",
        "# legal moves from s.  \n",
        "``` \n",
        "Verify the above two are nearly identical. \n",
        "1. Q.iloc[s,a]9\n",
        "2. Ersa.iloc[s,a] + args.gamma * ( ....+ p * Q.iloc[s_prime,:].max() + .... )    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzXRhY9o17l1"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Write your code to compute the above, in the code cell below, and print the Q table, and the Ersa.iloc[s,a]+ args.gamma* ... results here. \n",
        "\n",
        "(1) The code bleow computes the RHS of the equation and prints the Q table and RHS table as shown in the output below.\n",
        "\n",
        "(2) The total sum of the absolute difference between Q and RHS is $112.41$. And the averaged absolute difference for each $(s,a)$ pair is $3.63$, indicating that the equation is approximately correct. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae9JtoPo2Ol4",
        "outputId": "daa0317b-dadc-494e-854e-ea111eb043ca"
      },
      "source": [
        "# Write your code here.\n",
        "print('\\nQ table:\\n')\n",
        "print(Q)\n",
        "\n",
        "num_valid_pair = 0\n",
        "#compute the RHS of the equation\n",
        "RHS = delta.copy(deep=True) # initialization\n",
        "for ss in range(len(delta)):\n",
        "  for aa in range(len(delta.columns)):\n",
        "    \n",
        "    if ss==goal:\n",
        "      RHS.iloc[ss,aa]=0\n",
        "      continue\n",
        "    \n",
        "    if delta.iloc[ss,aa]==-1: #illegal action\n",
        "      RHS.iloc[ss,aa]=-1\n",
        "      continue\n",
        "\n",
        "    #calculate the p for ss,aa intended action\n",
        "    p=np.zeros(num_actions) \n",
        "    num_nonzero = (delta.iloc[ss,:]>=0).sum()\n",
        "    for d in range(num_actions):\n",
        "      if delta.iloc[ss,d]==-1: #illegal action\n",
        "        p[d]=0\n",
        "      else:\n",
        "        if d==aa:\n",
        "          p[d]=0.7\n",
        "        else:\n",
        "          p[d]=0.3/(num_nonzero-1)\n",
        "    \n",
        "    #sum the Pi*maxQ(s',a')\n",
        "    sum_PQ=0\n",
        "    for d in range(num_actions):\n",
        "      if delta.iloc[ss,d]==-1: #illegal action\n",
        "        continue\n",
        "      else:\n",
        "        s_prime = delta.iloc[ss,d]\n",
        "        sum_PQ += p[d]*Q.iloc[s_prime,:].max()\n",
        "    \n",
        "    # compute the RHS\n",
        "    RHS.iloc[ss,aa] = Ersa.iloc[ss,aa] + gamma * sum_PQ\n",
        "    num_valid_pair += 1\n",
        "\n",
        "print('\\nRHS table:\\n')\n",
        "print(RHS)\n",
        "\n",
        "diff = df_diff(RHS,Q)\n",
        "\n",
        "print('\\nSum difference = Sum|RHS -Q|:')\n",
        "print(diff)\n",
        "print('\\nNumber of valid (s,a) pairs in the Q table:')\n",
        "print(num_valid_pair)\n",
        "print('\\nAvg difference = Sum|RHS -Q|/num_valid_pair:')\n",
        "print(diff/num_valid_pair)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Q table:\n",
            "\n",
            "            up       down       left      right\n",
            "s0   -1.000000  45.009047  -1.000000  45.600779\n",
            "s1   -1.000000  55.700928  43.698898  52.846955\n",
            "s2   -1.000000  66.835231  54.442221  -1.000000\n",
            "s3   43.651295  52.728438  -1.000000  54.380871\n",
            "s4   52.518930  70.259005  51.838089  68.938673\n",
            "s5   63.504029  87.470739  64.083395  -1.000000\n",
            "s6   50.368310  52.878809  -1.000000  67.850724\n",
            "s7   63.725887  67.140945  60.170812  88.551735\n",
            "s8    0.000000   0.000000   0.000000   0.000000\n",
            "s9   58.155724  -1.000000  -1.000000  61.721953\n",
            "s10  72.833452  -1.000000  57.466564  75.638806\n",
            "s11  90.045263  -1.000000  74.475267  -1.000000\n",
            "\n",
            "RHS table:\n",
            "\n",
            "            up       down       left      right\n",
            "s0   -1.000000  49.299199  -1.000000  49.774420\n",
            "s1   -1.000000  59.442035  47.236212  57.747266\n",
            "s2   -1.000000  70.145816  58.708684  -1.000000\n",
            "s3   47.373304  58.387027  -1.000000  59.579126\n",
            "s4   55.827886  73.567321  55.115055  72.983584\n",
            "s5   66.524999  89.048804  65.811182  -1.000000\n",
            "s6   54.546896  58.180732  -1.000000  71.461474\n",
            "s7   67.386655  69.440612  65.626063  90.855405\n",
            "s8    0.000000   0.000000   0.000000   0.000000\n",
            "s9   63.168434  -1.000000  -1.000000  65.972143\n",
            "s10  76.276167  -1.000000  62.995425  77.015463\n",
            "s11  91.688300  -1.000000  75.752712  -1.000000\n",
            "\n",
            "Sum difference = Sum|RHS -Q|:\n",
            "112.40663002106797\n",
            "\n",
            "Number of valid (s,a) pairs in the Q table:\n",
            "31\n",
            "\n",
            "Avg difference = Sum|RHS -Q|/num_valid_pair:\n",
            "3.6260203232602572\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}